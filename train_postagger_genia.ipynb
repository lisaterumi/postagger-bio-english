{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GJKpwl_v4b1"
      },
      "source": [
        "# Treinando um modelo POS-Tagger com o corpus GENIA\n",
        "\n",
        "Baseado no código de Thiago Castro (https://www.youtube.com/user/Thicasfer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUZ04u5q2dpu"
      },
      "source": [
        "Vamos começar baixando as dependências"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1o7CjIu9UXE",
        "outputId": "2e884696-4406-4950-8949-988e361005c9"
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 26.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 66.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf098i9pde4m",
        "outputId": "fc957338-6531-46c4-c27c-c03eeb69cb8f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/My\\ Drive/postagger_genia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H68Z1Ql6dqZ6",
        "outputId": "ba700a38-7370-4874-fc6d-c3786fe6254c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/postagger_genia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "Vf8ZRmhfduyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d85bee0-524c-44d3-f19b-3e743f29c998"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENIAtest.pos  GENIAtrain.pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfoYwmza39MJ"
      },
      "source": [
        "**Treinamento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f7tKHPv5o_I"
      },
      "source": [
        "No caso, vamos treinar um *part-of-speech tagger*, i.e. um modelo que ache as classes gramaticais dos tokens de um texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLOMPUzy6aqp"
      },
      "source": [
        "Lendo o córpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEFSrr76OiMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4103c8-2c02-4b02-eb8b-60a2e53cc061"
      },
      "source": [
        "with open('GENIAtrain.pos') as f:\n",
        "  traindata = [[tuple(w.split('/'))for w in snt.split()] for snt in f.read().split('\\n')]\n",
        "\n",
        "with open('GENIAtest.pos') as f:\n",
        "  devdata = [[tuple(w.split('/'))for w in snt.split()] for snt in f.read().split('\\n')]\n",
        "\n",
        "devdata[2]"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AB', 'LS'),\n",
              " ('-', ':'),\n",
              " ('The', 'DT'),\n",
              " ('involvement', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('ion', 'NN'),\n",
              " ('channels', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('B', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('T', 'NN'),\n",
              " ('lymphocyte', 'NN'),\n",
              " ('activation', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('supported', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('many', 'JJ'),\n",
              " ('reports', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('changes', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('ion', 'NN'),\n",
              " ('fluxes', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('membrane', 'NN'),\n",
              " ('potential', 'NN'),\n",
              " ('after', 'IN'),\n",
              " ('mitogen', 'NN'),\n",
              " ('binding', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zlzlupdagy4",
        "outputId": "d10ddf5d-13b4-4194-838f-0cce0bb67a52"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('UI', 'LS'), ('-', ':'), ('95369245', 'CD')],\n",
              " [('TI', 'LS'),\n",
              "  ('-', ':'),\n",
              "  ('IL-2', 'NN'),\n",
              "  ('gene', 'NN'),\n",
              "  ('expression', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('NF-kappa', 'NN'),\n",
              "  ('B', 'NN'),\n",
              "  ('activation', 'NN'),\n",
              "  ('through', 'IN'),\n",
              "  ('CD28', 'NN'),\n",
              "  ('requires', 'VBZ'),\n",
              "  ('reactive', 'JJ'),\n",
              "  ('oxygen', 'NN'),\n",
              "  ('production', 'NN'),\n",
              "  ('by', 'IN'),\n",
              "  ('5-lipoxygenase', 'NN'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLYV360DSiSi"
      },
      "source": [
        "def parse(data):\n",
        "  X = list()\n",
        "  temp=''\n",
        "  for snt in data:\n",
        "    for w in snt:\n",
        "      if len(w)>1:\n",
        "        temp = temp+' '+w[0].strip()\n",
        "    if temp.strip():\n",
        "      X.append(temp.strip())\n",
        "    temp=''\n",
        "\n",
        "  temp=list()\n",
        "  y=list()\n",
        "  y2=list()\n",
        "  for snt in data:\n",
        "    for w in snt:\n",
        "      if len(w)>1:\n",
        "        a=w[-1]\n",
        "        if a=='' or a=='(' or a==')' or a==',' or a=='.' or a=='\"' or a=='\\'' or a==\"''\" or a=='``' or a==':' or a=='-':\n",
        "          a='PUNCT'\n",
        "        if '|' in a:\n",
        "          a = a.split('|')[0]\n",
        "        temp.append(a)\n",
        "        y2.append(a)\n",
        "    if len(temp)>0:\n",
        "      y.append(temp)\n",
        "    temp=list()\n",
        "       \n",
        "  y2 = list(set(y2))\n",
        "\n",
        "  return X, y, y2\n",
        "\n",
        "train_X, train_y, y2_train = parse(traindata)\n",
        "dev_X, dev_y, y2_dev = parse(devdata)"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id2tag(y2_train, y2_dev):\n",
        "  y2=y2_train + y2_dev\n",
        "  y2 = list(set(y2))\n",
        "  tags2 = [w.split('|')[0] for w in y2]\n",
        "  tags3=list()\n",
        "  for w in tags2:\n",
        "    tags3.append(w)\n",
        "  tags = list(set(tags3))\n",
        "  tags.append('<pad>')\n",
        "  tag2id = { tag:i for i, tag in enumerate(tags) }\n",
        "  id2tag = { i:tag for i, tag in enumerate(tags) }\n",
        "\n",
        "  return tag2id, id2tag\n",
        "\n",
        "tag2id, id2tag = id2tag(y2_train, y2_dev)\n"
      ],
      "metadata": {
        "id": "3PiT5W7qyHBP"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUlLYmJSyjUv",
        "outputId": "d35c592f-ebdf-4879-f397-e3a42ed46d6d"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'VBD': 0,\n",
              " 'N': 1,\n",
              " 'XT': 2,\n",
              " 'JJS': 3,\n",
              " 'E2A': 4,\n",
              " 'WRB': 5,\n",
              " 'VB': 6,\n",
              " 'TO': 7,\n",
              " 'VBP': 8,\n",
              " 'FW': 9,\n",
              " 'EX': 10,\n",
              " 'VBN': 11,\n",
              " 'VBZ': 12,\n",
              " 'NNS': 13,\n",
              " 'VBG': 14,\n",
              " 'RBR': 15,\n",
              " 'WP': 16,\n",
              " 'CT': 17,\n",
              " 'PRP': 18,\n",
              " 'JJR': 19,\n",
              " 'CC': 20,\n",
              " 'NNPS': 21,\n",
              " 'CD': 22,\n",
              " 'DT': 23,\n",
              " 'NNP': 24,\n",
              " 'PDT': 25,\n",
              " 'LS': 26,\n",
              " 'PP': 27,\n",
              " 'PRP$': 28,\n",
              " 'NN': 29,\n",
              " 'JJ': 30,\n",
              " 'RP': 31,\n",
              " 'RBS': 32,\n",
              " 'MD': 33,\n",
              " 'WP$': 34,\n",
              " 'RB': 35,\n",
              " 'SYM': 36,\n",
              " 'IN': 37,\n",
              " 'PUNCT': 38,\n",
              " 'WDT': 39,\n",
              " 'POS': 40,\n",
              " '<pad>': 41}"
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EL4iTAjDacQr",
        "outputId": "73199e64-22d5-4d3a-c096-ef8a5dc66d6e"
      },
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TI - E1A gene expression induces susceptibility to killing by NK cells following immortalization but not adenovirus infection of human cells .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y[20]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YXTSqjKbx1K",
        "outputId": "deb7bfcc-20a2-42ef-d5db-a47af242e570"
      },
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LS',\n",
              " 'PUNCT',\n",
              " 'NN',\n",
              " 'NN',\n",
              " 'NN',\n",
              " 'VBZ',\n",
              " 'NN',\n",
              " 'TO',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'NN',\n",
              " 'NNS',\n",
              " 'VBG',\n",
              " 'NN',\n",
              " 'CC',\n",
              " 'RB',\n",
              " 'NN',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'JJ',\n",
              " 'NNS',\n",
              " 'PUNCT']"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_X[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "NVlWlYmlaKCm",
        "outputId": "5f101882-4004-42f0-8350-b9a0c2e01537"
      },
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TI - Charybdotoxin-sensitive , Ca(2+)-dependent membrane potential changes are not involved in human T or B cell activation and proliferation .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6NXt26TaMTI",
        "outputId": "1239b71b-00e8-4ad6-e866-bf28fa474da7"
      },
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LS',\n",
              " 'PUNCT',\n",
              " 'JJ',\n",
              " 'PUNCT',\n",
              " 'JJ',\n",
              " 'NN',\n",
              " 'JJ',\n",
              " 'NNS',\n",
              " 'VBP',\n",
              " 'RB',\n",
              " 'VBN',\n",
              " 'IN',\n",
              " 'JJ',\n",
              " 'NN',\n",
              " 'CC',\n",
              " 'NN',\n",
              " 'NN',\n",
              " 'NN',\n",
              " 'CC',\n",
              " 'NN',\n",
              " 'PUNCT']"
            ]
          },
          "metadata": {},
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2tag "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1ajDlAzIRtC",
        "outputId": "088defb1-a314-4e67-a9f4-d48580fc6a14"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'VBD',\n",
              " 1: 'N',\n",
              " 2: 'XT',\n",
              " 3: 'JJS',\n",
              " 4: 'E2A',\n",
              " 5: 'WRB',\n",
              " 6: 'VB',\n",
              " 7: 'TO',\n",
              " 8: 'VBP',\n",
              " 9: 'FW',\n",
              " 10: 'EX',\n",
              " 11: 'VBN',\n",
              " 12: 'VBZ',\n",
              " 13: 'NNS',\n",
              " 14: 'VBG',\n",
              " 15: 'RBR',\n",
              " 16: 'WP',\n",
              " 17: 'CT',\n",
              " 18: 'PRP',\n",
              " 19: 'JJR',\n",
              " 20: 'CC',\n",
              " 21: 'NNPS',\n",
              " 22: 'CD',\n",
              " 23: 'DT',\n",
              " 24: 'NNP',\n",
              " 25: 'PDT',\n",
              " 26: 'LS',\n",
              " 27: 'PP',\n",
              " 28: 'PRP$',\n",
              " 29: 'NN',\n",
              " 30: 'JJ',\n",
              " 31: 'RP',\n",
              " 32: 'RBS',\n",
              " 33: 'MD',\n",
              " 34: 'WP$',\n",
              " 35: 'RB',\n",
              " 36: 'SYM',\n",
              " 37: 'IN',\n",
              " 38: 'PUNCT',\n",
              " 39: 'WDT',\n",
              " 40: 'POS',\n",
              " 41: '<pad>'}"
            ]
          },
          "metadata": {},
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo_zTcEl6964",
        "outputId": "9ea33fd4-184a-4469-8e16-824e4ad3320b"
      },
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'VBD': 0,\n",
              " 'N': 1,\n",
              " 'XT': 2,\n",
              " 'JJS': 3,\n",
              " 'E2A': 4,\n",
              " 'WRB': 5,\n",
              " 'VB': 6,\n",
              " 'TO': 7,\n",
              " 'VBP': 8,\n",
              " 'FW': 9,\n",
              " 'EX': 10,\n",
              " 'VBN': 11,\n",
              " 'VBZ': 12,\n",
              " 'NNS': 13,\n",
              " 'VBG': 14,\n",
              " 'RBR': 15,\n",
              " 'WP': 16,\n",
              " 'CT': 17,\n",
              " 'PRP': 18,\n",
              " 'JJR': 19,\n",
              " 'CC': 20,\n",
              " 'NNPS': 21,\n",
              " 'CD': 22,\n",
              " 'DT': 23,\n",
              " 'NNP': 24,\n",
              " 'PDT': 25,\n",
              " 'LS': 26,\n",
              " 'PP': 27,\n",
              " 'PRP$': 28,\n",
              " 'NN': 29,\n",
              " 'JJ': 30,\n",
              " 'RP': 31,\n",
              " 'RBS': 32,\n",
              " 'MD': 33,\n",
              " 'WP$': 34,\n",
              " 'RB': 35,\n",
              " 'SYM': 36,\n",
              " 'IN': 37,\n",
              " 'PUNCT': 38,\n",
              " 'WDT': 39,\n",
              " 'POS': 40,\n",
              " '<pad>': 41}"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfYxC95L6ooB",
        "outputId": "eeae0be4-fa45-43d6-97fa-7775c6d15ba6"
      },
      "source": [
        "print(train_X[:10])\n",
        "print(train_y[:10])"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['UI - 95369245', 'TI - IL-2 gene expression and NF-kappa B activation through CD28 requires reactive oxygen production by 5-lipoxygenase .', 'AB - Activation of the CD28 surface receptor provides a major costimulatory signal for T cell activation resulting in enhanced production of interleukin-2 ( IL-2 ) and cell proliferation .', 'In primary T lymphocytes we show that CD28 ligation leads to the rapid intracellular formation of reactive oxygen intermediates ( ROIs ) which are required for CD28-mediated activation of the NF-kappa B complex and IL-2 expression .', 'Delineation of the CD28 signaling cascade was found to involve protein tyrosine kinase activity , followed by the activation of phospholipase A2 and 5-lipoxygenase .', 'Our data suggest that lipoxygenase metabolites activate ROI formation which then induce IL-2 expression via NF-kappa B activation .', 'These findings should be useful for therapeutic strategies and the development of immunosuppressants targeting the CD28 costimulatory pathway .', 'UI - 95333264', 'TI - The peri-kappa B site mediates human immunodeficiency virus type 2 enhancer activation in monocytes but not in T cells .', 'AB - Human immunodeficiency virus type 2 ( HIV-2 ) , like HIV-1 , causes AIDS and is associated with AIDS cases primarily in West Africa .']\n",
            "[['LS', 'PUNCT', 'CD'], ['LS', 'PUNCT', 'NN', 'NN', 'NN', 'CC', 'NN', 'NN', 'NN', 'IN', 'NN', 'VBZ', 'JJ', 'NN', 'NN', 'IN', 'NN', 'PUNCT'], ['LS', 'PUNCT', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'VBZ', 'DT', 'JJ', 'JJ', 'NN', 'IN', 'NN', 'NN', 'NN', 'VBG', 'IN', 'VBN', 'NN', 'IN', 'NN', 'PUNCT', 'NN', 'PUNCT', 'CC', 'NN', 'NN', 'PUNCT'], ['IN', 'JJ', 'NN', 'NNS', 'PRP', 'VBP', 'IN', 'NN', 'NN', 'VBZ', 'TO', 'DT', 'JJ', 'JJ', 'NN', 'IN', 'JJ', 'NN', 'NNS', 'PUNCT', 'NNS', 'PUNCT', 'WDT', 'VBP', 'VBN', 'IN', 'JJ', 'NN', 'IN', 'DT', 'NN', 'JJ', 'NN', 'CC', 'NN', 'NN', 'PUNCT'], ['NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'VBD', 'VBN', 'TO', 'VB', 'NN', 'NN', 'NN', 'NN', 'PUNCT', 'VBN', 'IN', 'DT', 'NN', 'IN', 'NN', 'NN', 'CC', 'NN', 'PUNCT'], ['PRP$', 'NNS', 'VBP', 'IN', 'NN', 'NNS', 'VBP', 'NN', 'NN', 'WDT', 'RB', 'VBP', 'NN', 'NN', 'IN', 'NN', 'NN', 'NN', 'PUNCT'], ['DT', 'NNS', 'MD', 'VB', 'JJ', 'IN', 'JJ', 'NNS', 'CC', 'DT', 'NN', 'IN', 'NNS', 'VBG', 'DT', 'NN', 'NN', 'NN', 'PUNCT'], ['LS', 'PUNCT', 'CD'], ['LS', 'PUNCT', 'DT', 'NN', 'NN', 'NN', 'VBZ', 'JJ', 'NN', 'NN', 'NN', 'CD', 'NN', 'NN', 'IN', 'NNS', 'CC', 'RB', 'IN', 'NN', 'NNS', 'PUNCT'], ['LS', 'PUNCT', 'JJ', 'NN', 'NN', 'NN', 'CD', 'PUNCT', 'NN', 'PUNCT', 'PUNCT', 'IN', 'NN', 'PUNCT', 'VBZ', 'NN', 'CC', 'VBZ', 'VBN', 'IN', 'NN', 'NNS', 'RB', 'IN', 'NNP', 'NNP', 'PUNCT']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dev_X[:10])\n",
        "print(dev_y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roepNHkFDEyK",
        "outputId": "bcc30384-fef7-48c8-bc15-8f908d162bde"
      },
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['UI - 92043714', 'TI - Charybdotoxin-sensitive , Ca(2+)-dependent membrane potential changes are not involved in human T or B cell activation and proliferation .', 'AB - The involvement of ion channels in B and T lymphocyte activation is supported by many reports of changes in ion fluxes and membrane potential after mitogen binding .', 'Human T and B lymphocytes demonstrate an early and transient hyperpolarization after ligand binding .', 'Inasmuch as the change in membrane potential is dependent on elevation of free cytosolic calcium , the hyperpolarization is presumably through opening of Ca(2+)-stimulated K+ channels .', 'We have used charybdotoxin , a known inhibitor of Ca(2+)-dependent K+ channels , to study the role of these channels in lymphocyte activation and mitogenesis .', 'We demonstrate that charybdotoxin inhibits the ligand-induced transient membrane hyperpolarization in B and T cells in a dose-dependent fashion , without affecting changes in cytosolic Ca2+ .', 'However , blockade of the Ca(2+)-activated K+ channel is not associated with changes in cell-cycle gene activation , IL-2 production , IL-2R expression or B and T cell mitogenesis .', 'These results imply that membrane potential changes secondary to the ligand-dependent opening of Ca(2+)-activated K+ channels are not involved in B and T lymphocyte activation and mitogenesis .', 'UI - 92135145']\n",
            "[['LS', 'PUNCT', 'CD'], ['LS', 'PUNCT', 'JJ', 'PUNCT', 'JJ', 'NN', 'JJ', 'NNS', 'VBP', 'RB', 'VBN', 'IN', 'JJ', 'NN', 'CC', 'NN', 'NN', 'NN', 'CC', 'NN', 'PUNCT'], ['LS', 'PUNCT', 'DT', 'NN', 'IN', 'NN', 'NNS', 'IN', 'NN', 'CC', 'NN', 'NN', 'NN', 'VBZ', 'VBN', 'IN', 'JJ', 'NNS', 'IN', 'NNS', 'IN', 'NN', 'NNS', 'CC', 'NN', 'NN', 'IN', 'NN', 'NN', 'PUNCT'], ['JJ', 'NN', 'CC', 'NN', 'NNS', 'VBP', 'DT', 'JJ', 'CC', 'JJ', 'NN', 'IN', 'JJ', 'NN', 'PUNCT'], ['RB', 'IN', 'DT', 'NN', 'IN', 'NN', 'NN', 'VBZ', 'JJ', 'IN', 'NN', 'IN', 'JJ', 'JJ', 'NN', 'PUNCT', 'DT', 'NN', 'VBZ', 'RB', 'IN', 'NN', 'IN', 'JJ', 'NN', 'NNS', 'PUNCT'], ['PRP', 'VBP', 'VBN', 'NN', 'PUNCT', 'DT', 'JJ', 'NN', 'IN', 'JJ', 'NN', 'NNS', 'PUNCT', 'TO', 'VB', 'DT', 'NN', 'IN', 'DT', 'NNS', 'IN', 'NN', 'NN', 'CC', 'NN', 'PUNCT'], ['PRP', 'VBP', 'IN', 'NN', 'VBZ', 'DT', 'JJ', 'JJ', 'NN', 'NN', 'IN', 'NN', 'CC', 'NN', 'NNS', 'IN', 'DT', 'JJ', 'NN', 'PUNCT', 'IN', 'VBG', 'NNS', 'IN', 'JJ', 'NN', 'PUNCT'], ['RB', 'PUNCT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NN', 'VBZ', 'RB', 'VBN', 'IN', 'NNS', 'IN', 'JJ', 'NN', 'NN', 'PUNCT', 'NN', 'NN', 'PUNCT', 'NN', 'NN', 'CC', 'NN', 'CC', 'NN', 'NN', 'NN', 'PUNCT'], ['DT', 'NNS', 'VBP', 'IN', 'NN', 'JJ', 'NNS', 'JJ', 'TO', 'DT', 'JJ', 'NN', 'IN', 'JJ', 'NN', 'NNS', 'VBP', 'RB', 'VBN', 'IN', 'NN', 'CC', 'NN', 'NN', 'NN', 'CC', 'NN', 'PUNCT'], ['LS', 'PUNCT', 'CD']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1hO9DMZVnNH",
        "outputId": "668ba23b-1a86-4ffe-e4da-838fd4e3508f"
      },
      "source": [
        "# align\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def align(X, y):\n",
        "  tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2', do_lower_case=False)\n",
        "  \n",
        "  procdata = []\n",
        "  for (X_, y_) in zip(X, y):\n",
        "    inputs = tokenizer(X_, return_tensors=\"pt\")\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "\n",
        "    try:\n",
        "      new_tags = ['<pad>']\n",
        "      pos = 0\n",
        "      for token in tokens[1:-1]:\n",
        "        if '##' in token:\n",
        "          new_tags.append(y_[pos-1])\n",
        "        else:\n",
        "          new_tags.append(y_[pos])\n",
        "          pos += 1\n",
        "      new_tags.append('<pad>')\n",
        "\n",
        "      procdata.append({ 'X': X_, 'y': ' '.join(new_tags) })\n",
        "    except:\n",
        "      pass\n",
        "  return procdata\n",
        "\n",
        "trainset = align(train_X, train_y)\n",
        "devset = align(dev_X, dev_y)\n",
        "\n",
        "len(trainset), len(devset) "
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6229, 727)"
            ]
          },
          "metadata": {},
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdG0REEb7VIl"
      },
      "source": [
        "Importando dependências. Veja que utilizaremos os métodos `AutoTokenizer` e `AutoModelForTokenClassification` para instanciar o tokenizador e o modelo de classificação de tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmztB71FfsAP"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report"
      ],
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "devset[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuXDxqr0mhAT",
        "outputId": "f74ff2fc-e0ff-4eb3-866e-4689129d352b"
      },
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'X': 'UI - 92043714', 'y': '<pad> LS LS PUNCT CD CD CD CD CD <pad>'},\n",
              " {'X': 'AB - The involvement of ion channels in B and T lymphocyte activation is supported by many reports of changes in ion fluxes and membrane potential after mitogen binding .',\n",
              "  'y': '<pad> LS PUNCT DT NN IN NN NNS IN NN CC NN NN NN NN NN NN VBZ VBN IN JJ NNS IN NNS IN NN NNS NNS CC NN NN IN NN NN NN PUNCT <pad>'},\n",
              " {'X': 'Human T and B lymphocytes demonstrate an early and transient hyperpolarization after ligand binding .',\n",
              "  'y': '<pad> JJ NN CC NN NNS NNS NNS VBP DT JJ CC JJ JJ NN NN NN NN NN IN JJ JJ JJ NN PUNCT <pad>'},\n",
              " {'X': 'UI - 92135145', 'y': '<pad> LS LS PUNCT CD CD CD CD <pad>'}]"
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxp6t147pT8y",
        "outputId": "015b7ab7-b127-49ed-b6e6-861099b56073"
      },
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'X': 'UI - 95369245', 'y': '<pad> LS LS PUNCT CD CD CD CD CD <pad>'},\n",
              " {'X': 'These findings should be useful for therapeutic strategies and the development of immunosuppressants targeting the CD28 costimulatory pathway .',\n",
              "  'y': '<pad> DT NNS MD VB JJ IN JJ NNS CC DT NN IN NNS NNS NNS NNS NNS NNS VBG DT NN NN NN NN NN NN PUNCT <pad>'},\n",
              " {'X': 'UI - 95333264', 'y': '<pad> LS LS PUNCT CD CD CD CD <pad>'},\n",
              " {'X': 'UI - 95343554', 'y': '<pad> LS LS PUNCT CD CD CD CD CD <pad>'},\n",
              " {'X': 'TI - E1A gene expression induces susceptibility to killing by NK cells following immortalization but not adenovirus infection of human cells .',\n",
              "  'y': '<pad> LS LS PUNCT NN NN NN NN NN VBZ VBZ NN NN NN NN NN TO NN IN NN NN NNS VBG NN NN CC RB NN NN NN NN IN JJ NNS PUNCT <pad>'},\n",
              " {'X': 'AB - Adenovirus ( Ad ) infection and E1A transfection were used to model changes in susceptibility to NK cell killing caused by transient vs stable E1A expression in human cells .',\n",
              "  'y': '<pad> LS PUNCT NN NN NN NN PUNCT NN PUNCT NN CC NN NN NN NN NN NN VBD VBN TO VB NNS IN NN NN NN NN NN TO NN NN NN NN VBN IN JJ JJ CC JJ NN NN NN NN IN JJ NNS PUNCT <pad>'},\n",
              " {'X': 'The inability of E1A gene products to induce cytolytic susceptibility during infection was not explained by an inhibitory effect of viral infection on otherwise susceptible target cells or by viral gene effects on class I MHC antigen expression on target cells .',\n",
              "  'y': '<pad> DT NN IN NN NN NN NN NNS TO VB JJ JJ JJ JJ NN NN NN NN NN IN NN VBD RB VBN IN DT JJ JJ NN IN JJ NN IN RB JJ NN NNS CC IN JJ NN NNS IN NN CD NN NN NN NN NN IN NN NNS PUNCT <pad>'},\n",
              " {'X': 'UI - 95347379', 'y': '<pad> LS LS PUNCT CD CD CD CD CD <pad>'}]"
            ]
          },
          "metadata": {},
          "execution_count": 351
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTnkqQ_H7iv5"
      },
      "source": [
        "Definindo parâmetros do modelo e treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xIR5mAhZ8TV"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "nclasses = len(tag2id)\n",
        "nepochs = 30\n",
        "batch_size = 32\n",
        "batch_status = 32\n",
        "learning_rate = 1e-5\n",
        "\n",
        "early_stop = 3\n",
        "max_length = 200\n",
        "write_path = 'model'"
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0-Ks4_D7l7o"
      },
      "source": [
        "Separando os dados em batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcYh4FR3hGDi"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "traindata = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "devdata = DataLoader(devset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "devdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6vfqWxsp5Ms",
        "outputId": "0c72736b-5e7d-4755-8df8-a7d30cdc640f"
      },
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f3c04382410>"
            ]
          },
          "metadata": {},
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TInOepxE7tDx"
      },
      "source": [
        "Inicializando tokenizador, modelo, função de erro e otimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IttWMB6ohQ2w",
        "outputId": "3082904a-3c2d-415a-b63c-386a4b93c961"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2', do_lower_case=False)\n",
        "model = AutoModelForTokenClassification.from_pretrained('dmis-lab/biobert-base-cased-v1.2', num_labels=nclasses).to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.2 were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nclasses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gacxUY23ewVz",
        "outputId": "36e6f945-18e5-4fe6-9f72-8d608c2415ae"
      },
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-UvXTnF7xdN"
      },
      "source": [
        "Método de Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pakJtpBXl24V"
      },
      "source": [
        "def evaluate(model, testdata):\n",
        "  model.eval()\n",
        "  y_real, y_pred = [], []\n",
        "  for batch_idx, inp in enumerate(testdata):\n",
        "    texts = inp['X']\n",
        "\n",
        "    labels = []\n",
        "    for tags in inp['y']:\n",
        "      tag_idxs = [tag2id[tag] for tag in tags.split()]\n",
        "      labels.append(tag_idxs)\n",
        "    \n",
        "    # classifying\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(device)\n",
        "    output = model(**inputs)\n",
        "                \n",
        "    pred_labels = torch.argmax(output.logits, 2).tolist()\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "      y_real.extend(labels[i][1:-1])\n",
        "      seq_size = len(labels[i][1:-1])\n",
        "      y_pred.extend(pred_labels[i][1:seq_size+1])\n",
        "    \n",
        "    if (batch_idx+1) % batch_status == 0:\n",
        "      print('Progress:', round(batch_idx / len(testdata), 2), batch_idx)\n",
        "  \n",
        "  print(classification_report(y_real, y_pred))\n",
        "  f1 = f1_score(y_real, y_pred, average='weighted')\n",
        "  acc = accuracy_score(y_real, y_pred)\n",
        "  return f1, acc"
      ],
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoiEwiRN72m4"
      },
      "source": [
        "Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1gyFXXEhdN0",
        "outputId": "4db2b47c-c362-4012-94c3-d108cfe4692d"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "max_f1, repeat = 0, 0\n",
        "num=-1\n",
        "for epoch in range(nepochs):\n",
        "  model.train()\n",
        "  losses = []\n",
        "  for batch_idx, inp in enumerate(traindata):\n",
        "    num=num+1\n",
        "    texts = inp['X']\n",
        "    \n",
        "    labels = []\n",
        "    for tags in inp['y']:\n",
        "      try:\n",
        "        tag_idxs = [tag2id[tag] for tag in tags.split()]\n",
        "        labels.append(torch.tensor(tag_idxs[:max_length]))\n",
        "      except:\n",
        "        print('inp[y]:', inp['y'])\n",
        "        print('texts:', texts)\n",
        "        print('num:', num)\n",
        "        raise\n",
        "    \n",
        "    labels= pad_sequence(labels, padding_value=tag2id['<pad>']).transpose(0, 1).unsqueeze(0).contiguous()\n",
        "\n",
        "    # classifying\n",
        "    try:\n",
        "      inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(device)\n",
        "      output = model(**inputs, labels=labels.to(device))\n",
        "    except:\n",
        "        print('inp[y]:', inp['y'])\n",
        "        print('texts:', texts)\n",
        "        print('inputs:', inputs)\n",
        "        print('batch_idx:', batch_idx)\n",
        "        raise\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = output.loss\n",
        "    losses.append(float(loss))\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Display\n",
        "    if (batch_idx+1) % batch_status == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTotal Loss: {:.6f}'.format(epoch, \\\n",
        "        batch_idx+1, len(traindata), 100. * batch_idx / len(traindata), \n",
        "        float(loss), round(sum(losses) / len(losses), 5)))\n",
        "  \n",
        "  f1, acc = evaluate(model, devdata)\n",
        "  print('F1: ', f1, 'Accuracy: ', acc)\n",
        "  if f1 > max_f1:\n",
        "    model.save_pretrained(os.path.join(write_path, 'model'))\n",
        "    max_f1 = f1\n",
        "    repeat = 0\n",
        "    print('Saving best model...')\n",
        "  else:\n",
        "    repeat += 1\n",
        "  \n",
        "  if repeat == early_stop:\n",
        "    print('FIM!!! early_stop')\n",
        "    break"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [32/195 (16%)]\tLoss: 1.613525\tTotal Loss: 2.221850\n",
            "Train Epoch: 0 [64/195 (32%)]\tLoss: 0.527869\tTotal Loss: 1.603140\n",
            "Train Epoch: 0 [96/195 (49%)]\tLoss: 0.647523\tTotal Loss: 1.297910\n",
            "Train Epoch: 0 [128/195 (65%)]\tLoss: 0.464864\tTotal Loss: 1.096860\n",
            "Train Epoch: 0 [160/195 (82%)]\tLoss: 0.236420\tTotal Loss: 0.938370\n",
            "Train Epoch: 0 [192/195 (98%)]\tLoss: 0.217300\tTotal Loss: 0.817430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.91      0.91       263\n",
            "           3       0.00      0.00      0.00        14\n",
            "           5       0.00      0.00      0.00         8\n",
            "           6       0.94      0.91      0.92       169\n",
            "           7       1.00      0.91      0.95       203\n",
            "           8       0.89      0.94      0.92       195\n",
            "           9       1.00      0.11      0.20        98\n",
            "          10       0.00      0.00      0.00         5\n",
            "          11       0.73      0.81      0.77       532\n",
            "          12       0.88      1.00      0.93       252\n",
            "          13       0.97      0.97      0.97      1575\n",
            "          14       0.00      0.00      0.00       133\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.00      0.00      0.00         3\n",
            "          18       1.00      0.65      0.79        69\n",
            "          19       0.00      0.00      0.00        22\n",
            "          20       0.98      0.91      0.95       395\n",
            "          22       1.00      0.87      0.93      1328\n",
            "          23       0.87      0.99      0.93       987\n",
            "          24       0.00      0.00      0.00         6\n",
            "          26       1.00      0.99      0.99       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       0.00      0.00      0.00        39\n",
            "          29       0.93      0.98      0.95      5674\n",
            "          30       0.83      0.88      0.85      2075\n",
            "          31       0.00      0.00      0.00         7\n",
            "          32       0.00      0.00      0.00         5\n",
            "          33       0.00      0.00      0.00        58\n",
            "          34       0.00      0.00      0.00         2\n",
            "          35       0.81      0.65      0.72       336\n",
            "          37       0.93      1.00      0.97      1579\n",
            "          38       0.99      1.00      1.00      1446\n",
            "          39       1.00      0.12      0.22        57\n",
            "\n",
            "    accuracy                           0.92     18165\n",
            "   macro avg       0.54      0.47      0.48     18165\n",
            "weighted avg       0.91      0.92      0.91     18165\n",
            "\n",
            "F1:  0.9112601028010472 Accuracy:  0.9222130470685383\n",
            "Saving best model...\n",
            "Train Epoch: 1 [32/195 (16%)]\tLoss: 0.116702\tTotal Loss: 0.140550\n",
            "Train Epoch: 1 [64/195 (32%)]\tLoss: 0.134715\tTotal Loss: 0.126580\n",
            "Train Epoch: 1 [96/195 (49%)]\tLoss: 0.082134\tTotal Loss: 0.113860\n",
            "Train Epoch: 1 [128/195 (65%)]\tLoss: 0.064110\tTotal Loss: 0.103170\n",
            "Train Epoch: 1 [160/195 (82%)]\tLoss: 0.044544\tTotal Loss: 0.094900\n",
            "Train Epoch: 1 [192/195 (98%)]\tLoss: 0.039683\tTotal Loss: 0.088930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97       263\n",
            "           3       0.00      0.00      0.00        14\n",
            "           5       0.00      0.00      0.00         8\n",
            "           6       0.98      0.98      0.98       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.98      0.97      0.98       195\n",
            "           9       1.00      0.56      0.72        98\n",
            "          10       0.00      0.00      0.00         5\n",
            "          11       0.91      0.97      0.94       532\n",
            "          12       0.98      1.00      0.99       252\n",
            "          13       0.99      0.97      0.98      1575\n",
            "          14       0.90      0.89      0.90       133\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.00      0.00      0.00         3\n",
            "          18       0.92      1.00      0.96        69\n",
            "          19       0.00      0.00      0.00        22\n",
            "          20       0.99      0.98      0.99       395\n",
            "          22       0.99      0.99      0.99      1328\n",
            "          23       0.99      1.00      0.99       987\n",
            "          24       0.00      0.00      0.00         6\n",
            "          26       1.00      0.99      0.99       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      0.95      0.97        39\n",
            "          29       0.97      0.99      0.98      5674\n",
            "          30       0.95      0.94      0.94      2075\n",
            "          31       0.00      0.00      0.00         7\n",
            "          32       0.00      0.00      0.00         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       0.00      0.00      0.00         2\n",
            "          35       0.89      0.95      0.92       336\n",
            "          37       0.99      1.00      0.99      1579\n",
            "          38       0.99      1.00      1.00      1446\n",
            "          39       0.92      0.98      0.95        57\n",
            "\n",
            "    accuracy                           0.97     18165\n",
            "   macro avg       0.65      0.64      0.64     18165\n",
            "weighted avg       0.97      0.97      0.97     18165\n",
            "\n",
            "F1:  0.9713923949157046 Accuracy:  0.973850812001101\n",
            "Saving best model...\n",
            "Train Epoch: 2 [32/195 (16%)]\tLoss: 0.025525\tTotal Loss: 0.045300\n",
            "Train Epoch: 2 [64/195 (32%)]\tLoss: 0.068424\tTotal Loss: 0.044880\n",
            "Train Epoch: 2 [96/195 (49%)]\tLoss: 0.021883\tTotal Loss: 0.045160\n",
            "Train Epoch: 2 [128/195 (65%)]\tLoss: 0.025065\tTotal Loss: 0.043490\n",
            "Train Epoch: 2 [160/195 (82%)]\tLoss: 0.040823\tTotal Loss: 0.041400\n",
            "Train Epoch: 2 [192/195 (98%)]\tLoss: 0.021191\tTotal Loss: 0.040570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       263\n",
            "           3       1.00      0.21      0.35        14\n",
            "           5       0.00      0.00      0.00         8\n",
            "           6       0.98      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      0.99      0.99       195\n",
            "           9       0.92      0.89      0.90        98\n",
            "          10       1.00      0.60      0.75         5\n",
            "          11       0.92      0.98      0.95       532\n",
            "          12       0.99      1.00      0.99       252\n",
            "          13       0.99      0.98      0.98      1575\n",
            "          14       0.88      0.94      0.91       133\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.00      0.00      0.00         3\n",
            "          18       0.93      1.00      0.97        69\n",
            "          19       0.91      0.45      0.61        22\n",
            "          20       0.99      1.00      0.99       395\n",
            "          22       0.99      1.00      0.99      1328\n",
            "          23       0.99      0.99      0.99       987\n",
            "          24       0.00      0.00      0.00         6\n",
            "          26       1.00      0.99      0.99       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.98      5674\n",
            "          30       0.96      0.95      0.95      2075\n",
            "          31       0.00      0.00      0.00         7\n",
            "          32       0.00      0.00      0.00         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       0.00      0.00      0.00         2\n",
            "          35       0.93      0.94      0.94       336\n",
            "          37       0.99      1.00      0.99      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       0.90      0.98      0.94        57\n",
            "\n",
            "    accuracy                           0.98     18165\n",
            "   macro avg       0.73      0.69      0.70     18165\n",
            "weighted avg       0.98      0.98      0.98     18165\n",
            "\n",
            "F1:  0.9778949809218422 Accuracy:  0.9793008532892926\n",
            "Saving best model...\n",
            "Train Epoch: 3 [32/195 (16%)]\tLoss: 0.032062\tTotal Loss: 0.028380\n",
            "Train Epoch: 3 [64/195 (32%)]\tLoss: 0.022534\tTotal Loss: 0.026880\n",
            "Train Epoch: 3 [96/195 (49%)]\tLoss: 0.058064\tTotal Loss: 0.027120\n",
            "Train Epoch: 3 [128/195 (65%)]\tLoss: 0.034333\tTotal Loss: 0.028740\n",
            "Train Epoch: 3 [160/195 (82%)]\tLoss: 0.037011\tTotal Loss: 0.028250\n",
            "Train Epoch: 3 [192/195 (98%)]\tLoss: 0.021378\tTotal Loss: 0.027760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       263\n",
            "           3       1.00      0.71      0.83        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.98      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.98      1.00      0.99       195\n",
            "           9       0.94      0.85      0.89        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.95      0.97      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.98      1575\n",
            "          14       0.94      0.91      0.92       133\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.00      0.00      0.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       0.66      0.95      0.78        22\n",
            "          20       0.99      1.00      0.99       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      0.99      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.98      5674\n",
            "          30       0.97      0.95      0.96      2075\n",
            "          31       0.00      0.00      0.00         7\n",
            "          32       1.00      0.60      0.75         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       0.00      0.00      0.00         2\n",
            "          35       0.95      0.95      0.95       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       0.92      0.98      0.95        57\n",
            "\n",
            "    accuracy                           0.98     18165\n",
            "   macro avg       0.82      0.81      0.81     18165\n",
            "weighted avg       0.98      0.98      0.98     18165\n",
            "\n",
            "F1:  0.9826509106359474 Accuracy:  0.9832645196807046\n",
            "Saving best model...\n",
            "Train Epoch: 4 [32/195 (16%)]\tLoss: 0.027532\tTotal Loss: 0.021310\n",
            "Train Epoch: 4 [64/195 (32%)]\tLoss: 0.033531\tTotal Loss: 0.024200\n",
            "Train Epoch: 4 [96/195 (49%)]\tLoss: 0.013341\tTotal Loss: 0.022430\n",
            "Train Epoch: 4 [128/195 (65%)]\tLoss: 0.043532\tTotal Loss: 0.022280\n",
            "Train Epoch: 4 [160/195 (82%)]\tLoss: 0.023729\tTotal Loss: 0.021910\n",
            "Train Epoch: 4 [192/195 (98%)]\tLoss: 0.027107\tTotal Loss: 0.022550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       263\n",
            "           3       0.92      0.79      0.85        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.99      1.00       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      1.00       195\n",
            "           9       0.99      0.78      0.87        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.94      0.98      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       1.00      0.98      0.99      1575\n",
            "          14       0.93      0.94      0.93       133\n",
            "          15       0.75      0.33      0.46         9\n",
            "          16       0.00      0.00      0.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       0.72      0.95      0.82        22\n",
            "          20       0.99      1.00      0.99       395\n",
            "          22       1.00      0.99      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.98      5674\n",
            "          30       0.97      0.95      0.96      2075\n",
            "          31       0.00      0.00      0.00         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       0.00      0.00      0.00         2\n",
            "          35       0.96      0.96      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       0.92      0.98      0.95        57\n",
            "\n",
            "    accuracy                           0.98     18165\n",
            "   macro avg       0.84      0.83      0.83     18165\n",
            "weighted avg       0.98      0.98      0.98     18165\n",
            "\n",
            "F1:  0.9830574949001595 Accuracy:  0.9835397742912194\n",
            "Saving best model...\n",
            "Train Epoch: 5 [32/195 (16%)]\tLoss: 0.037354\tTotal Loss: 0.020470\n",
            "Train Epoch: 5 [64/195 (32%)]\tLoss: 0.031613\tTotal Loss: 0.018750\n",
            "Train Epoch: 5 [96/195 (49%)]\tLoss: 0.018277\tTotal Loss: 0.017920\n",
            "Train Epoch: 5 [128/195 (65%)]\tLoss: 0.021127\tTotal Loss: 0.016970\n",
            "Train Epoch: 5 [160/195 (82%)]\tLoss: 0.017886\tTotal Loss: 0.018120\n",
            "Train Epoch: 5 [192/195 (98%)]\tLoss: 0.009246\tTotal Loss: 0.018880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       263\n",
            "           3       0.92      0.86      0.89        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      0.99       195\n",
            "           9       0.94      0.89      0.91        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.94      0.97      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       1.00      0.98      0.99      1575\n",
            "          14       0.93      0.94      0.93       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       0.00      0.00      0.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       0.91      0.95      0.93        22\n",
            "          20       0.99      1.00      1.00       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       0.97      1.00      0.99        39\n",
            "          29       0.98      0.99      0.99      5674\n",
            "          30       0.97      0.96      0.96      2075\n",
            "          31       0.00      0.00      0.00         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       0.00      0.00      0.00         2\n",
            "          35       0.96      0.96      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       0.93      0.98      0.96        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.85      0.85      0.85     18165\n",
            "weighted avg       0.98      0.99      0.99     18165\n",
            "\n",
            "F1:  0.9850028340012505 Accuracy:  0.9853564547206166\n",
            "Saving best model...\n",
            "Train Epoch: 6 [32/195 (16%)]\tLoss: 0.009714\tTotal Loss: 0.019250\n",
            "Train Epoch: 6 [64/195 (32%)]\tLoss: 0.014246\tTotal Loss: 0.019300\n",
            "Train Epoch: 6 [96/195 (49%)]\tLoss: 0.025269\tTotal Loss: 0.018250\n",
            "Train Epoch: 6 [128/195 (65%)]\tLoss: 0.011894\tTotal Loss: 0.017060\n",
            "Train Epoch: 6 [160/195 (82%)]\tLoss: 0.022558\tTotal Loss: 0.016530\n",
            "Train Epoch: 6 [192/195 (98%)]\tLoss: 0.017195\tTotal Loss: 0.015780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       0.99      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      1.00       195\n",
            "           9       0.95      0.88      0.91        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.95      0.98      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.99      1575\n",
            "          14       0.95      0.95      0.95       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      0.67      0.80         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      0.99      0.99       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.98      5674\n",
            "          30       0.97      0.95      0.96      2075\n",
            "          31       0.00      0.00      0.00         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       0.00      0.00      0.00         2\n",
            "          35       0.97      0.95      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       0.95      0.98      0.97        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.89      0.88      0.88     18165\n",
            "weighted avg       0.98      0.99      0.98     18165\n",
            "\n",
            "F1:  0.9848256328105626 Accuracy:  0.9851362510322048\n",
            "Train Epoch: 7 [32/195 (16%)]\tLoss: 0.008528\tTotal Loss: 0.015510\n",
            "Train Epoch: 7 [64/195 (32%)]\tLoss: 0.007690\tTotal Loss: 0.016900\n",
            "Train Epoch: 7 [96/195 (49%)]\tLoss: 0.007228\tTotal Loss: 0.015720\n",
            "Train Epoch: 7 [128/195 (65%)]\tLoss: 0.019716\tTotal Loss: 0.014810\n",
            "Train Epoch: 7 [160/195 (82%)]\tLoss: 0.025919\tTotal Loss: 0.014160\n",
            "Train Epoch: 7 [192/195 (98%)]\tLoss: 0.012442\tTotal Loss: 0.013870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       0.99      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      0.99      0.99       195\n",
            "           9       0.94      0.86      0.90        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.96      0.98      0.97       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.98      1575\n",
            "          14       0.93      0.95      0.94       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      1.00      0.99       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      0.99      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.98      5674\n",
            "          30       0.97      0.96      0.96      2075\n",
            "          31       0.00      0.00      0.00         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.96      0.96      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.92      0.92      0.92     18165\n",
            "weighted avg       0.99      0.99      0.99     18165\n",
            "\n",
            "F1:  0.9853251344251158 Accuracy:  0.9855766584090283\n",
            "Saving best model...\n",
            "Train Epoch: 8 [32/195 (16%)]\tLoss: 0.002555\tTotal Loss: 0.013120\n",
            "Train Epoch: 8 [64/195 (32%)]\tLoss: 0.011937\tTotal Loss: 0.012560\n",
            "Train Epoch: 8 [96/195 (49%)]\tLoss: 0.007405\tTotal Loss: 0.011710\n",
            "Train Epoch: 8 [128/195 (65%)]\tLoss: 0.009728\tTotal Loss: 0.011230\n",
            "Train Epoch: 8 [160/195 (82%)]\tLoss: 0.008005\tTotal Loss: 0.011170\n",
            "Train Epoch: 8 [192/195 (98%)]\tLoss: 0.011501\tTotal Loss: 0.011850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       0.99      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      0.99      0.99       195\n",
            "           9       0.93      0.78      0.84        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.97      0.96      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.97      0.98      1575\n",
            "          14       0.94      0.95      0.95       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      1.00      0.99       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      0.99      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.98      0.98      5674\n",
            "          30       0.96      0.97      0.96      2075\n",
            "          31       0.00      0.00      0.00         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.95      0.96      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.98     18165\n",
            "   macro avg       0.92      0.91      0.92     18165\n",
            "weighted avg       0.98      0.98      0.98     18165\n",
            "\n",
            "F1:  0.9837142635513717 Accuracy:  0.9839801816680429\n",
            "Train Epoch: 9 [32/195 (16%)]\tLoss: 0.010045\tTotal Loss: 0.010910\n",
            "Train Epoch: 9 [64/195 (32%)]\tLoss: 0.018725\tTotal Loss: 0.011500\n",
            "Train Epoch: 9 [96/195 (49%)]\tLoss: 0.014160\tTotal Loss: 0.010690\n",
            "Train Epoch: 9 [128/195 (65%)]\tLoss: 0.007747\tTotal Loss: 0.010510\n",
            "Train Epoch: 9 [160/195 (82%)]\tLoss: 0.002745\tTotal Loss: 0.010760\n",
            "Train Epoch: 9 [192/195 (98%)]\tLoss: 0.003998\tTotal Loss: 0.010710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.98      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      0.99       195\n",
            "           9       1.00      0.64      0.78        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.97      0.96      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       1.00      0.98      0.99      1575\n",
            "          14       0.97      0.92      0.95       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      1.00      0.99       395\n",
            "          22       1.00      0.99      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.97      0.99      0.98      5674\n",
            "          30       0.97      0.96      0.96      2075\n",
            "          31       1.00      0.29      0.44         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.97      0.96      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.98     18165\n",
            "   macro avg       0.95      0.92      0.93     18165\n",
            "weighted avg       0.98      0.98      0.98     18165\n",
            "\n",
            "F1:  0.9842214139438797 Accuracy:  0.9845306908890724\n",
            "Train Epoch: 10 [32/195 (16%)]\tLoss: 0.005260\tTotal Loss: 0.013590\n",
            "Train Epoch: 10 [64/195 (32%)]\tLoss: 0.003315\tTotal Loss: 0.010950\n",
            "Train Epoch: 10 [96/195 (49%)]\tLoss: 0.006090\tTotal Loss: 0.009910\n",
            "Train Epoch: 10 [128/195 (65%)]\tLoss: 0.009261\tTotal Loss: 0.010420\n",
            "Train Epoch: 10 [160/195 (82%)]\tLoss: 0.003659\tTotal Loss: 0.009790\n",
            "Train Epoch: 10 [192/195 (98%)]\tLoss: 0.082241\tTotal Loss: 0.009740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      1.00       195\n",
            "           9       0.94      0.92      0.93        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.96      0.98      0.97       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.98      1575\n",
            "          14       0.96      0.95      0.96       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      1.00      0.99       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      0.99      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.98      5674\n",
            "          30       0.97      0.96      0.96      2075\n",
            "          31       1.00      0.71      0.83         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.96      0.95      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.95      0.94      0.94     18165\n",
            "weighted avg       0.99      0.99      0.99     18165\n",
            "\n",
            "F1:  0.9856882290436957 Accuracy:  0.9857418111753372\n",
            "Saving best model...\n",
            "Train Epoch: 11 [32/195 (16%)]\tLoss: 0.002663\tTotal Loss: 0.005420\n",
            "Train Epoch: 11 [64/195 (32%)]\tLoss: 0.004740\tTotal Loss: 0.007190\n",
            "Train Epoch: 11 [96/195 (49%)]\tLoss: 0.013537\tTotal Loss: 0.008370\n",
            "Train Epoch: 11 [128/195 (65%)]\tLoss: 0.004776\tTotal Loss: 0.008810\n",
            "Train Epoch: 11 [160/195 (82%)]\tLoss: 0.004509\tTotal Loss: 0.008400\n",
            "Train Epoch: 11 [192/195 (98%)]\tLoss: 0.004357\tTotal Loss: 0.008490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.98      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      0.99       195\n",
            "           9       0.94      0.90      0.92        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.96      0.97      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.98      1575\n",
            "          14       0.97      0.95      0.96       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      0.99      0.99       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.99      5674\n",
            "          30       0.97      0.96      0.96      2075\n",
            "          31       1.00      0.43      0.60         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.96      0.96      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.95      0.93      0.94     18165\n",
            "weighted avg       0.99      0.99      0.99     18165\n",
            "\n",
            "F1:  0.9861011012992618 Accuracy:  0.9861822185521607\n",
            "Saving best model...\n",
            "Train Epoch: 12 [32/195 (16%)]\tLoss: 0.011160\tTotal Loss: 0.006390\n",
            "Train Epoch: 12 [64/195 (32%)]\tLoss: 0.024024\tTotal Loss: 0.008490\n",
            "Train Epoch: 12 [96/195 (49%)]\tLoss: 0.005762\tTotal Loss: 0.007260\n",
            "Train Epoch: 12 [128/195 (65%)]\tLoss: 0.004524\tTotal Loss: 0.007020\n",
            "Train Epoch: 12 [160/195 (82%)]\tLoss: 0.006741\tTotal Loss: 0.007740\n",
            "Train Epoch: 12 [192/195 (98%)]\tLoss: 0.005392\tTotal Loss: 0.007710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      1.00       195\n",
            "           9       0.93      0.92      0.92        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.97      0.95      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.98      1575\n",
            "          14       0.98      0.93      0.96       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      1.00      0.99       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.98      5674\n",
            "          30       0.96      0.96      0.96      2075\n",
            "          31       1.00      0.71      0.83         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.97      0.96      0.97       336\n",
            "          37       1.00      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.95      0.94      0.94     18165\n",
            "weighted avg       0.99      0.99      0.99     18165\n",
            "\n",
            "F1:  0.9854708425895501 Accuracy:  0.9855216074869254\n",
            "Train Epoch: 13 [32/195 (16%)]\tLoss: 0.001580\tTotal Loss: 0.004790\n",
            "Train Epoch: 13 [64/195 (32%)]\tLoss: 0.004067\tTotal Loss: 0.006880\n",
            "Train Epoch: 13 [96/195 (49%)]\tLoss: 0.003005\tTotal Loss: 0.008040\n",
            "Train Epoch: 13 [128/195 (65%)]\tLoss: 0.004737\tTotal Loss: 0.007500\n",
            "Train Epoch: 13 [160/195 (82%)]\tLoss: 0.001708\tTotal Loss: 0.007190\n",
            "Train Epoch: 13 [192/195 (98%)]\tLoss: 0.002223\tTotal Loss: 0.006900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      0.99       195\n",
            "           9       0.95      0.84      0.89        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.95      0.98      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.98      1575\n",
            "          14       0.96      0.97      0.96       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      0.99      0.99       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.98      5674\n",
            "          30       0.97      0.96      0.96      2075\n",
            "          31       1.00      0.71      0.83         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.96      0.96      0.96       336\n",
            "          37       1.00      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.95      0.94      0.94     18165\n",
            "weighted avg       0.99      0.99      0.99     18165\n",
            "\n",
            "F1:  0.9861045608067894 Accuracy:  0.9861822185521607\n",
            "Saving best model...\n",
            "Train Epoch: 14 [32/195 (16%)]\tLoss: 0.002557\tTotal Loss: 0.005590\n",
            "Train Epoch: 14 [64/195 (32%)]\tLoss: 0.001521\tTotal Loss: 0.005860\n",
            "Train Epoch: 14 [96/195 (49%)]\tLoss: 0.008140\tTotal Loss: 0.006270\n",
            "Train Epoch: 14 [128/195 (65%)]\tLoss: 0.008118\tTotal Loss: 0.005620\n",
            "Train Epoch: 14 [160/195 (82%)]\tLoss: 0.001451\tTotal Loss: 0.005710\n",
            "Train Epoch: 14 [192/195 (98%)]\tLoss: 0.002999\tTotal Loss: 0.006230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       0.98      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      0.99      0.99       195\n",
            "           9       0.96      0.91      0.93        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.97      0.95      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.98      1575\n",
            "          14       0.96      0.95      0.95       133\n",
            "          15       0.80      0.89      0.84         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      0.99      0.99       395\n",
            "          22       1.00      0.99      1.00      1328\n",
            "          23       1.00      0.99      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.98      5674\n",
            "          30       0.96      0.97      0.96      2075\n",
            "          31       1.00      0.29      0.44         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.97      0.95      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.95      0.93      0.93     18165\n",
            "weighted avg       0.99      0.99      0.99     18165\n",
            "\n",
            "F1:  0.9850828399052095 Accuracy:  0.9851913019543077\n",
            "Train Epoch: 15 [32/195 (16%)]\tLoss: 0.004838\tTotal Loss: 0.004470\n",
            "Train Epoch: 15 [64/195 (32%)]\tLoss: 0.001649\tTotal Loss: 0.005740\n",
            "Train Epoch: 15 [96/195 (49%)]\tLoss: 0.110854\tTotal Loss: 0.006550\n",
            "Train Epoch: 15 [128/195 (65%)]\tLoss: 0.001385\tTotal Loss: 0.006060\n",
            "Train Epoch: 15 [160/195 (82%)]\tLoss: 0.008179\tTotal Loss: 0.005950\n",
            "Train Epoch: 15 [192/195 (98%)]\tLoss: 0.001736\tTotal Loss: 0.005920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      1.00       195\n",
            "           9       0.95      0.92      0.93        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.96      0.97      0.97       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.99      1575\n",
            "          14       0.96      0.95      0.96       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      0.99      0.99       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          25       0.00      0.00      0.00         0\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.99      5674\n",
            "          30       0.97      0.96      0.96      2075\n",
            "          31       1.00      0.71      0.83         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.96      0.96      0.96       336\n",
            "          37       1.00      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.92      0.91      0.92     18165\n",
            "weighted avg       0.99      0.99      0.99     18165\n",
            "\n",
            "F1:  0.9864366954662949 Accuracy:  0.9864574731626755\n",
            "Saving best model...\n",
            "Train Epoch: 16 [32/195 (16%)]\tLoss: 0.002848\tTotal Loss: 0.006840\n",
            "Train Epoch: 16 [64/195 (32%)]\tLoss: 0.001290\tTotal Loss: 0.004890\n",
            "Train Epoch: 16 [96/195 (49%)]\tLoss: 0.010614\tTotal Loss: 0.004630\n",
            "Train Epoch: 16 [128/195 (65%)]\tLoss: 0.004294\tTotal Loss: 0.004940\n",
            "Train Epoch: 16 [160/195 (82%)]\tLoss: 0.001332\tTotal Loss: 0.004940\n",
            "Train Epoch: 16 [192/195 (98%)]\tLoss: 0.001308\tTotal Loss: 0.005000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.98      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.98      1.00      0.99       195\n",
            "           9       0.95      0.92      0.93        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.96      0.97      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.98      1575\n",
            "          14       0.96      0.96      0.96       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      1.00      0.99       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      0.99      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          25       0.00      0.00      0.00         0\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.99      5674\n",
            "          30       0.97      0.96      0.96      2075\n",
            "          31       1.00      0.71      0.83         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.96      0.96      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.92      0.91      0.92     18165\n",
            "weighted avg       0.99      0.99      0.99     18165\n",
            "\n",
            "F1:  0.986268931941784 Accuracy:  0.9862923203963666\n",
            "Train Epoch: 17 [32/195 (16%)]\tLoss: 0.008614\tTotal Loss: 0.004500\n",
            "Train Epoch: 17 [64/195 (32%)]\tLoss: 0.001040\tTotal Loss: 0.003690\n",
            "Train Epoch: 17 [96/195 (49%)]\tLoss: 0.005653\tTotal Loss: 0.003470\n",
            "Train Epoch: 17 [128/195 (65%)]\tLoss: 0.000907\tTotal Loss: 0.003600\n",
            "Train Epoch: 17 [160/195 (82%)]\tLoss: 0.001921\tTotal Loss: 0.004200\n",
            "Train Epoch: 17 [192/195 (98%)]\tLoss: 0.001033\tTotal Loss: 0.004030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      1.00       195\n",
            "           9       0.94      0.90      0.92        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.95      0.98      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.98      1575\n",
            "          14       0.97      0.95      0.96       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      1.00      1.00       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          25       0.00      0.00      0.00         0\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.99      5674\n",
            "          30       0.97      0.96      0.96      2075\n",
            "          31       1.00      0.71      0.83         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.96      0.96      0.96       336\n",
            "          37       1.00      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      1.00      1.00        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.92      0.91      0.92     18165\n",
            "weighted avg       0.99      0.99      0.99     18165\n",
            "\n",
            "F1:  0.9862093208097338 Accuracy:  0.9862372694742637\n",
            "Train Epoch: 18 [32/195 (16%)]\tLoss: 0.003019\tTotal Loss: 0.002270\n",
            "Train Epoch: 18 [64/195 (32%)]\tLoss: 0.005232\tTotal Loss: 0.002430\n",
            "Train Epoch: 18 [96/195 (49%)]\tLoss: 0.001697\tTotal Loss: 0.003080\n",
            "Train Epoch: 18 [128/195 (65%)]\tLoss: 0.000745\tTotal Loss: 0.002920\n",
            "Train Epoch: 18 [160/195 (82%)]\tLoss: 0.005289\tTotal Loss: 0.003080\n",
            "Train Epoch: 18 [192/195 (98%)]\tLoss: 0.001206\tTotal Loss: 0.003470\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       263\n",
            "           3       0.93      1.00      0.97        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       0.99      0.99      0.99       169\n",
            "           7       1.00      1.00      1.00       203\n",
            "           8       0.99      1.00      1.00       195\n",
            "           9       0.95      0.78      0.85        98\n",
            "          10       0.83      1.00      0.91         5\n",
            "          11       0.96      0.97      0.96       532\n",
            "          12       1.00      1.00      1.00       252\n",
            "          13       0.99      0.98      0.99      1575\n",
            "          14       0.95      0.95      0.95       133\n",
            "          15       0.89      0.89      0.89         9\n",
            "          16       1.00      1.00      1.00         3\n",
            "          18       0.99      1.00      0.99        69\n",
            "          19       1.00      0.95      0.98        22\n",
            "          20       0.99      1.00      1.00       395\n",
            "          22       1.00      1.00      1.00      1328\n",
            "          23       1.00      1.00      1.00       987\n",
            "          24       1.00      1.00      1.00         6\n",
            "          25       0.00      0.00      0.00         0\n",
            "          26       1.00      1.00      1.00       620\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       1.00      1.00      1.00        39\n",
            "          29       0.98      0.99      0.98      5674\n",
            "          30       0.97      0.96      0.96      2075\n",
            "          31       1.00      0.71      0.83         7\n",
            "          32       1.00      0.80      0.89         5\n",
            "          33       1.00      1.00      1.00        58\n",
            "          34       1.00      1.00      1.00         2\n",
            "          35       0.96      0.96      0.96       336\n",
            "          37       0.99      1.00      1.00      1579\n",
            "          38       1.00      1.00      1.00      1446\n",
            "          39       1.00      0.98      0.99        57\n",
            "\n",
            "    accuracy                           0.99     18165\n",
            "   macro avg       0.92      0.91      0.91     18165\n",
            "weighted avg       0.99      0.99      0.99     18165\n",
            "\n",
            "F1:  0.985267446136761 Accuracy:  0.9853564547206166\n",
            "FIM!!! early_stop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2tag #atual"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwJdsDBGDbOg",
        "outputId": "144dd06b-ebd5-45d4-8c1a-954654eab8e1"
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'VBD',\n",
              " 1: 'N',\n",
              " 2: 'XT',\n",
              " 3: 'JJS',\n",
              " 4: 'E2A',\n",
              " 5: 'WRB',\n",
              " 6: 'VB',\n",
              " 7: 'TO',\n",
              " 8: 'VBP',\n",
              " 9: 'FW',\n",
              " 10: 'EX',\n",
              " 11: 'VBN',\n",
              " 12: 'VBZ',\n",
              " 13: 'NNS',\n",
              " 14: 'VBG',\n",
              " 15: 'RBR',\n",
              " 16: 'WP',\n",
              " 17: 'CT',\n",
              " 18: 'PRP',\n",
              " 19: 'JJR',\n",
              " 20: 'CC',\n",
              " 21: 'NNPS',\n",
              " 22: 'CD',\n",
              " 23: 'DT',\n",
              " 24: 'NNP',\n",
              " 25: 'PDT',\n",
              " 26: 'LS',\n",
              " 27: 'PP',\n",
              " 28: 'PRP$',\n",
              " 29: 'NN',\n",
              " 30: 'JJ',\n",
              " 31: 'RP',\n",
              " 32: 'RBS',\n",
              " 33: 'MD',\n",
              " 34: 'WP$',\n",
              " 35: 'RB',\n",
              " 36: 'SYM',\n",
              " 37: 'IN',\n",
              " 38: 'PUNCT',\n",
              " 39: 'WDT',\n",
              " 40: 'POS',\n",
              " 41: '<pad>'}"
            ]
          },
          "metadata": {},
          "execution_count": 363
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls model/model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYpUylbNxdAt",
        "outputId": "11292161-91e1-40f0-d7dc-72392aa38cb4"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json  pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(os.path.join(write_path, 'model'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgRTTUniCcuR",
        "outputId": "b48025e2-69b5-4e08-cb18-32260e67e344"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model/model/tokenizer_config.json',\n",
              " 'model/model/special_tokens_map.json',\n",
              " 'model/model/vocab.txt',\n",
              " 'model/model/added_tokens.json',\n",
              " 'model/model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "model.to('cpu')\n",
        "nlp_token_class = pipeline('ner', model=model, tokenizer=tokenizer, grouped_entities=True)\n",
        "\n",
        "nlp_token_class('AB - T cell receptor ( TCR ) stimulation induces rapid tyrosine phosphorylation of cellular proteins , including Cbl , a protooncogene product whose function remains unclear .')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKEtjQYCggbg",
        "outputId": "00d6d33d-7ba4-40db-b1d0-3fa9f70070bf"
      },
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/pipelines/token_classification.py:136: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
            "  \"`grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_26',\n",
              "  'score': 0.99950683,\n",
              "  'word': 'AB',\n",
              "  'start': 0,\n",
              "  'end': 2},\n",
              " {'entity_group': 'LABEL_38',\n",
              "  'score': 0.99941576,\n",
              "  'word': '-',\n",
              "  'start': 3,\n",
              "  'end': 4},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.8576849,\n",
              "  'word': 'T cell receptor',\n",
              "  'start': 5,\n",
              "  'end': 20},\n",
              " {'entity_group': 'LABEL_38',\n",
              "  'score': 0.47593167,\n",
              "  'word': '(',\n",
              "  'start': 21,\n",
              "  'end': 22},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.6770358,\n",
              "  'word': 'TCR',\n",
              "  'start': 23,\n",
              "  'end': 26},\n",
              " {'entity_group': 'LABEL_38',\n",
              "  'score': 0.5545236,\n",
              "  'word': ')',\n",
              "  'start': 27,\n",
              "  'end': 28},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.9354885,\n",
              "  'word': 'stimulation',\n",
              "  'start': 29,\n",
              "  'end': 40},\n",
              " {'entity_group': 'LABEL_12',\n",
              "  'score': 0.99714565,\n",
              "  'word': 'induces',\n",
              "  'start': 41,\n",
              "  'end': 48},\n",
              " {'entity_group': 'LABEL_30',\n",
              "  'score': 0.99940205,\n",
              "  'word': 'rapid',\n",
              "  'start': 49,\n",
              "  'end': 54},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.9977628,\n",
              "  'word': 'tyrosine phosphorylation',\n",
              "  'start': 55,\n",
              "  'end': 79},\n",
              " {'entity_group': 'LABEL_37',\n",
              "  'score': 0.9421877,\n",
              "  'word': 'of',\n",
              "  'start': 80,\n",
              "  'end': 82},\n",
              " {'entity_group': 'LABEL_30',\n",
              "  'score': 0.99937755,\n",
              "  'word': 'cellular',\n",
              "  'start': 83,\n",
              "  'end': 91},\n",
              " {'entity_group': 'LABEL_13',\n",
              "  'score': 0.728341,\n",
              "  'word': 'proteins',\n",
              "  'start': 92,\n",
              "  'end': 100},\n",
              " {'entity_group': 'LABEL_38',\n",
              "  'score': 0.9985512,\n",
              "  'word': ',',\n",
              "  'start': 101,\n",
              "  'end': 102},\n",
              " {'entity_group': 'LABEL_14',\n",
              "  'score': 0.9964851,\n",
              "  'word': 'including',\n",
              "  'start': 103,\n",
              "  'end': 112},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.9937981,\n",
              "  'word': 'Cbl',\n",
              "  'start': 113,\n",
              "  'end': 116},\n",
              " {'entity_group': 'LABEL_38',\n",
              "  'score': 0.9981359,\n",
              "  'word': ',',\n",
              "  'start': 117,\n",
              "  'end': 118},\n",
              " {'entity_group': 'LABEL_23',\n",
              "  'score': 0.9982102,\n",
              "  'word': 'a',\n",
              "  'start': 119,\n",
              "  'end': 120},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.99447507,\n",
              "  'word': 'protooncogene product',\n",
              "  'start': 121,\n",
              "  'end': 142},\n",
              " {'entity_group': 'LABEL_34',\n",
              "  'score': 0.909454,\n",
              "  'word': 'whose',\n",
              "  'start': 143,\n",
              "  'end': 148},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.9953843,\n",
              "  'word': 'function',\n",
              "  'start': 149,\n",
              "  'end': 157},\n",
              " {'entity_group': 'LABEL_12',\n",
              "  'score': 0.998262,\n",
              "  'word': 'remains',\n",
              "  'start': 158,\n",
              "  'end': 165},\n",
              " {'entity_group': 'LABEL_30',\n",
              "  'score': 0.9995023,\n",
              "  'word': 'unclear',\n",
              "  'start': 166,\n",
              "  'end': 173},\n",
              " {'entity_group': 'LABEL_38',\n",
              "  'score': 0.9984085,\n",
              "  'word': '.',\n",
              "  'start': 174,\n",
              "  'end': 175}]"
            ]
          },
          "metadata": {},
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-V7R0-UEGuW",
        "outputId": "0bb1d9cc-010c-44b2-bdb7-2d5bc815b9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macmorpho-dev.txt   macmorpho-train.txt  model-bertimbau\n",
            "macmorpho-test.txt  model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "max_f1, repeat = 0, 0\n",
        "for epoch in range(nepochs):\n",
        "  model.train()\n",
        "  losses = []\n",
        "  for batch_idx, inp in enumerate(traindata):\n",
        "    texts = inp['X']\n",
        "    \n",
        "    labels = []\n",
        "    for tags in inp['y']:\n",
        "      tag_idxs = [tag2id[tag] for tag in tags.split()]\n",
        "      labels.append(torch.tensor(tag_idxs[:max_length]))\n",
        "    \n",
        "    labels= pad_sequence(labels, padding_value=tag2id['<pad>']).transpose(0, 1).unsqueeze(0).contiguous()\n",
        "\n",
        "    # classifying\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(device)\n",
        "    output = model(**inputs, labels=labels.to(device))\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = output.loss\n",
        "    losses.append(float(loss))\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Display\n",
        "    if (batch_idx+1) % batch_status == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTotal Loss: {:.6f}'.format(epoch, \\\n",
        "        batch_idx+1, len(traindata), 100. * batch_idx / len(traindata), \n",
        "        float(loss), round(sum(losses) / len(losses), 5)))\n",
        "  \n",
        "  f1, acc = evaluate(model, devdata)\n",
        "  print('F1: ', f1, 'Accuracy: ', acc)\n",
        "  if f1 > max_f1:\n",
        "    model.save_pretrained(os.path.join(write_path, 'model'))\n",
        "    max_f1 = f1\n",
        "    repeat = 0\n",
        "    print('Saving best model...')\n",
        "  else:\n",
        "    repeat += 1\n",
        "  \n",
        "  if repeat == early_stop:\n",
        "    print('FIM!!! early_stop')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIjv6Q2nDt93",
        "outputId": "ed52ebe0-db9f-4710-f308-29e841b7f8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [32/920 (3%)]\tLoss: 1.461453\tTotal Loss: 1.819320\n",
            "Train Epoch: 0 [64/920 (7%)]\tLoss: 0.511152\tTotal Loss: 1.358300\n",
            "Train Epoch: 0 [96/920 (10%)]\tLoss: 0.673721\tTotal Loss: 1.125050\n",
            "Train Epoch: 0 [128/920 (14%)]\tLoss: 0.273466\tTotal Loss: 0.954640\n",
            "Train Epoch: 0 [160/920 (17%)]\tLoss: 0.322064\tTotal Loss: 0.816940\n",
            "Train Epoch: 0 [192/920 (21%)]\tLoss: 0.173374\tTotal Loss: 0.712960\n",
            "Train Epoch: 0 [224/920 (24%)]\tLoss: 0.156140\tTotal Loss: 0.633830\n",
            "Train Epoch: 0 [256/920 (28%)]\tLoss: 0.145916\tTotal Loss: 0.569420\n",
            "Train Epoch: 0 [288/920 (31%)]\tLoss: 0.103741\tTotal Loss: 0.518190\n",
            "Train Epoch: 0 [320/920 (35%)]\tLoss: 0.115934\tTotal Loss: 0.476300\n",
            "Train Epoch: 0 [352/920 (38%)]\tLoss: 0.080446\tTotal Loss: 0.441740\n",
            "Train Epoch: 0 [384/920 (42%)]\tLoss: 0.097398\tTotal Loss: 0.411800\n",
            "Train Epoch: 0 [416/920 (45%)]\tLoss: 0.054918\tTotal Loss: 0.386390\n",
            "Train Epoch: 0 [448/920 (49%)]\tLoss: 0.055491\tTotal Loss: 0.364100\n",
            "Train Epoch: 0 [480/920 (52%)]\tLoss: 0.059967\tTotal Loss: 0.344600\n",
            "Train Epoch: 0 [512/920 (56%)]\tLoss: 0.050355\tTotal Loss: 0.327020\n",
            "Train Epoch: 0 [544/920 (59%)]\tLoss: 0.047645\tTotal Loss: 0.311640\n",
            "Train Epoch: 0 [576/920 (62%)]\tLoss: 0.046367\tTotal Loss: 0.297950\n",
            "Train Epoch: 0 [608/920 (66%)]\tLoss: 0.067590\tTotal Loss: 0.285610\n",
            "Train Epoch: 0 [640/920 (69%)]\tLoss: 0.102527\tTotal Loss: 0.274400\n",
            "Train Epoch: 0 [672/920 (73%)]\tLoss: 0.083018\tTotal Loss: 0.264110\n",
            "Train Epoch: 0 [704/920 (76%)]\tLoss: 0.055324\tTotal Loss: 0.254730\n",
            "Train Epoch: 0 [736/920 (80%)]\tLoss: 0.043065\tTotal Loss: 0.246250\n",
            "Train Epoch: 0 [768/920 (83%)]\tLoss: 0.036802\tTotal Loss: 0.237990\n",
            "Train Epoch: 0 [800/920 (87%)]\tLoss: 0.024511\tTotal Loss: 0.230380\n",
            "Train Epoch: 0 [832/920 (90%)]\tLoss: 0.049402\tTotal Loss: 0.223520\n",
            "Train Epoch: 0 [864/920 (94%)]\tLoss: 0.049337\tTotal Loss: 0.217140\n",
            "Train Epoch: 0 [896/920 (97%)]\tLoss: 0.040634\tTotal Loss: 0.211020\n",
            "Progress: 0.62 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96       512\n",
            "           1       0.88      0.88      0.88       340\n",
            "           2       0.84      0.89      0.86        61\n",
            "           3       0.86      0.48      0.62        25\n",
            "           4       0.96      0.98      0.97      4234\n",
            "           5       0.90      0.90      0.90       200\n",
            "           6       0.96      0.94      0.95       519\n",
            "           7       0.97      0.95      0.96      1340\n",
            "           8       0.99      0.98      0.99       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.98      0.98      2777\n",
            "          11       0.93      0.90      0.91       989\n",
            "          12       0.87      0.94      0.90       355\n",
            "          13       0.99      0.99      0.99      2273\n",
            "          14       0.98      0.97      0.98      9937\n",
            "          15       0.95      1.00      0.98       306\n",
            "          16       0.00      0.00      0.00        24\n",
            "          18       0.94      0.95      0.95      2465\n",
            "          19       0.00      0.00      0.00        16\n",
            "          20       0.98      0.99      0.99      1815\n",
            "          21       0.86      0.85      0.85       259\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.00      0.00      0.00        26\n",
            "          24       0.99      1.00      0.99      5004\n",
            "          25       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.97     38320\n",
            "   macro avg       0.75      0.74      0.74     38320\n",
            "weighted avg       0.97      0.97      0.97     38320\n",
            "\n",
            "F1:  0.972153093485554 Accuracy:  0.9732254697286012\n",
            "Saving best model...\n",
            "Train Epoch: 1 [32/920 (3%)]\tLoss: 0.043299\tTotal Loss: 0.043330\n",
            "Train Epoch: 1 [64/920 (7%)]\tLoss: 0.051893\tTotal Loss: 0.045030\n",
            "Train Epoch: 1 [96/920 (10%)]\tLoss: 0.034491\tTotal Loss: 0.044930\n",
            "Train Epoch: 1 [128/920 (14%)]\tLoss: 0.030608\tTotal Loss: 0.044710\n",
            "Train Epoch: 1 [160/920 (17%)]\tLoss: 0.046533\tTotal Loss: 0.044700\n",
            "Train Epoch: 1 [192/920 (21%)]\tLoss: 0.045929\tTotal Loss: 0.043880\n",
            "Train Epoch: 1 [224/920 (24%)]\tLoss: 0.016909\tTotal Loss: 0.043780\n",
            "Train Epoch: 1 [256/920 (28%)]\tLoss: 0.031826\tTotal Loss: 0.043050\n",
            "Train Epoch: 1 [288/920 (31%)]\tLoss: 0.043162\tTotal Loss: 0.043050\n",
            "Train Epoch: 1 [320/920 (35%)]\tLoss: 0.060900\tTotal Loss: 0.042820\n",
            "Train Epoch: 1 [352/920 (38%)]\tLoss: 0.067125\tTotal Loss: 0.042780\n",
            "Train Epoch: 1 [384/920 (42%)]\tLoss: 0.045049\tTotal Loss: 0.042710\n",
            "Train Epoch: 1 [416/920 (45%)]\tLoss: 0.022945\tTotal Loss: 0.042360\n",
            "Train Epoch: 1 [448/920 (49%)]\tLoss: 0.028917\tTotal Loss: 0.042050\n",
            "Train Epoch: 1 [480/920 (52%)]\tLoss: 0.063039\tTotal Loss: 0.041880\n",
            "Train Epoch: 1 [512/920 (56%)]\tLoss: 0.031452\tTotal Loss: 0.041460\n",
            "Train Epoch: 1 [544/920 (59%)]\tLoss: 0.022059\tTotal Loss: 0.041020\n",
            "Train Epoch: 1 [576/920 (62%)]\tLoss: 0.018156\tTotal Loss: 0.040610\n",
            "Train Epoch: 1 [608/920 (66%)]\tLoss: 0.011224\tTotal Loss: 0.040260\n",
            "Train Epoch: 1 [640/920 (69%)]\tLoss: 0.026570\tTotal Loss: 0.039990\n",
            "Train Epoch: 1 [672/920 (73%)]\tLoss: 0.026184\tTotal Loss: 0.039670\n",
            "Train Epoch: 1 [704/920 (76%)]\tLoss: 0.029676\tTotal Loss: 0.039560\n",
            "Train Epoch: 1 [736/920 (80%)]\tLoss: 0.022498\tTotal Loss: 0.039420\n",
            "Train Epoch: 1 [768/920 (83%)]\tLoss: 0.038008\tTotal Loss: 0.039370\n",
            "Train Epoch: 1 [800/920 (87%)]\tLoss: 0.059744\tTotal Loss: 0.039060\n",
            "Train Epoch: 1 [832/920 (90%)]\tLoss: 0.021563\tTotal Loss: 0.038940\n",
            "Train Epoch: 1 [864/920 (94%)]\tLoss: 0.018425\tTotal Loss: 0.038710\n",
            "Train Epoch: 1 [896/920 (97%)]\tLoss: 0.079046\tTotal Loss: 0.038620\n",
            "Progress: 0.62 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       512\n",
            "           1       0.87      0.93      0.90       340\n",
            "           2       0.96      0.90      0.93        61\n",
            "           3       0.88      0.56      0.68        25\n",
            "           4       0.97      0.98      0.97      4234\n",
            "           5       0.88      0.92      0.90       200\n",
            "           6       0.97      0.97      0.97       519\n",
            "           7       0.98      0.97      0.98      1340\n",
            "           8       0.97      0.99      0.98       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.96      0.90      0.93       989\n",
            "          12       0.91      0.94      0.93       355\n",
            "          13       0.99      1.00      0.99      2273\n",
            "          14       0.98      0.98      0.98      9937\n",
            "          15       0.97      0.99      0.98       306\n",
            "          16       1.00      0.71      0.83        24\n",
            "          18       0.96      0.96      0.96      2465\n",
            "          19       1.00      0.06      0.12        16\n",
            "          20       0.99      0.99      0.99      1815\n",
            "          21       0.90      0.86      0.88       259\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.52      0.65      0.58        26\n",
            "          24       0.99      1.00      0.99      5004\n",
            "          25       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.86      0.81      0.82     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.977632676189147 Accuracy:  0.978027139874739\n",
            "Saving best model...\n",
            "Train Epoch: 2 [32/920 (3%)]\tLoss: 0.028432\tTotal Loss: 0.034170\n",
            "Train Epoch: 2 [64/920 (7%)]\tLoss: 0.018925\tTotal Loss: 0.031850\n",
            "Train Epoch: 2 [96/920 (10%)]\tLoss: 0.008400\tTotal Loss: 0.030460\n",
            "Train Epoch: 2 [128/920 (14%)]\tLoss: 0.026733\tTotal Loss: 0.030130\n",
            "Train Epoch: 2 [160/920 (17%)]\tLoss: 0.024883\tTotal Loss: 0.030030\n",
            "Train Epoch: 2 [192/920 (21%)]\tLoss: 0.035951\tTotal Loss: 0.029930\n",
            "Train Epoch: 2 [224/920 (24%)]\tLoss: 0.021639\tTotal Loss: 0.029770\n",
            "Train Epoch: 2 [256/920 (28%)]\tLoss: 0.016523\tTotal Loss: 0.030000\n",
            "Train Epoch: 2 [288/920 (31%)]\tLoss: 0.036151\tTotal Loss: 0.029720\n",
            "Train Epoch: 2 [320/920 (35%)]\tLoss: 0.033000\tTotal Loss: 0.029670\n",
            "Train Epoch: 2 [352/920 (38%)]\tLoss: 0.022550\tTotal Loss: 0.029570\n",
            "Train Epoch: 2 [384/920 (42%)]\tLoss: 0.026401\tTotal Loss: 0.029440\n",
            "Train Epoch: 2 [416/920 (45%)]\tLoss: 0.022336\tTotal Loss: 0.029500\n",
            "Train Epoch: 2 [448/920 (49%)]\tLoss: 0.016584\tTotal Loss: 0.029530\n",
            "Train Epoch: 2 [480/920 (52%)]\tLoss: 0.022853\tTotal Loss: 0.029510\n",
            "Train Epoch: 2 [512/920 (56%)]\tLoss: 0.022634\tTotal Loss: 0.029590\n",
            "Train Epoch: 2 [544/920 (59%)]\tLoss: 0.020398\tTotal Loss: 0.029480\n",
            "Train Epoch: 2 [576/920 (62%)]\tLoss: 0.034670\tTotal Loss: 0.029540\n",
            "Train Epoch: 2 [608/920 (66%)]\tLoss: 0.019678\tTotal Loss: 0.029490\n",
            "Train Epoch: 2 [640/920 (69%)]\tLoss: 0.046996\tTotal Loss: 0.029440\n",
            "Train Epoch: 2 [672/920 (73%)]\tLoss: 0.013233\tTotal Loss: 0.029430\n",
            "Train Epoch: 2 [704/920 (76%)]\tLoss: 0.056208\tTotal Loss: 0.029390\n",
            "Train Epoch: 2 [736/920 (80%)]\tLoss: 0.011420\tTotal Loss: 0.029210\n",
            "Train Epoch: 2 [768/920 (83%)]\tLoss: 0.024678\tTotal Loss: 0.029210\n",
            "Train Epoch: 2 [800/920 (87%)]\tLoss: 0.049532\tTotal Loss: 0.029230\n",
            "Train Epoch: 2 [832/920 (90%)]\tLoss: 0.015287\tTotal Loss: 0.029140\n",
            "Train Epoch: 2 [864/920 (94%)]\tLoss: 0.020862\tTotal Loss: 0.029120\n",
            "Train Epoch: 2 [896/920 (97%)]\tLoss: 0.025412\tTotal Loss: 0.029010\n",
            "Progress: 0.62 31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       512\n",
            "           1       0.91      0.92      0.92       340\n",
            "           2       0.96      0.90      0.93        61\n",
            "           3       0.90      0.76      0.83        25\n",
            "           4       0.98      0.98      0.98      4234\n",
            "           5       0.91      0.91      0.91       200\n",
            "           6       0.97      0.97      0.97       519\n",
            "           7       0.98      0.98      0.98      1340\n",
            "           8       0.98      0.99      0.99       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.95      0.92      0.94       989\n",
            "          12       0.92      0.95      0.93       355\n",
            "          13       0.99      1.00      0.99      2273\n",
            "          14       0.98      0.98      0.98      9937\n",
            "          15       0.99      1.00      0.99       306\n",
            "          16       0.95      0.88      0.91        24\n",
            "          18       0.96      0.97      0.96      2465\n",
            "          19       0.75      0.38      0.50        16\n",
            "          20       0.99      0.99      0.99      1815\n",
            "          21       0.92      0.88      0.90       259\n",
            "          22       1.00      0.86      0.92         7\n",
            "          23       0.66      0.73      0.69        26\n",
            "          24       0.99      1.00      0.99      5004\n",
            "          25       1.00      0.38      0.55         8\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.94      0.89      0.91     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.9808153721764321 Accuracy:  0.9809237995824635\n",
            "Saving best model...\n",
            "Train Epoch: 3 [32/920 (3%)]\tLoss: 0.032004\tTotal Loss: 0.021700\n",
            "Train Epoch: 3 [64/920 (7%)]\tLoss: 0.023211\tTotal Loss: 0.021730\n",
            "Train Epoch: 3 [96/920 (10%)]\tLoss: 0.023393\tTotal Loss: 0.022380\n",
            "Train Epoch: 3 [128/920 (14%)]\tLoss: 0.027914\tTotal Loss: 0.021920\n",
            "Train Epoch: 3 [160/920 (17%)]\tLoss: 0.021631\tTotal Loss: 0.022470\n",
            "Train Epoch: 3 [192/920 (21%)]\tLoss: 0.030548\tTotal Loss: 0.022180\n",
            "Train Epoch: 3 [224/920 (24%)]\tLoss: 0.022173\tTotal Loss: 0.022490\n",
            "Train Epoch: 3 [256/920 (28%)]\tLoss: 0.032705\tTotal Loss: 0.022640\n",
            "Train Epoch: 3 [288/920 (31%)]\tLoss: 0.008437\tTotal Loss: 0.022910\n",
            "Train Epoch: 3 [320/920 (35%)]\tLoss: 0.032297\tTotal Loss: 0.022960\n",
            "Train Epoch: 3 [352/920 (38%)]\tLoss: 0.022518\tTotal Loss: 0.023160\n",
            "Train Epoch: 3 [384/920 (42%)]\tLoss: 0.018570\tTotal Loss: 0.023130\n",
            "Train Epoch: 3 [416/920 (45%)]\tLoss: 0.086752\tTotal Loss: 0.023170\n",
            "Train Epoch: 3 [448/920 (49%)]\tLoss: 0.022262\tTotal Loss: 0.023020\n",
            "Train Epoch: 3 [480/920 (52%)]\tLoss: 0.018145\tTotal Loss: 0.023010\n",
            "Train Epoch: 3 [512/920 (56%)]\tLoss: 0.027118\tTotal Loss: 0.023010\n",
            "Train Epoch: 3 [544/920 (59%)]\tLoss: 0.021256\tTotal Loss: 0.022920\n",
            "Train Epoch: 3 [576/920 (62%)]\tLoss: 0.011874\tTotal Loss: 0.023020\n",
            "Train Epoch: 3 [608/920 (66%)]\tLoss: 0.016011\tTotal Loss: 0.022970\n",
            "Train Epoch: 3 [640/920 (69%)]\tLoss: 0.015769\tTotal Loss: 0.023000\n",
            "Train Epoch: 3 [672/920 (73%)]\tLoss: 0.009626\tTotal Loss: 0.022910\n",
            "Train Epoch: 3 [704/920 (76%)]\tLoss: 0.027317\tTotal Loss: 0.023030\n",
            "Train Epoch: 3 [736/920 (80%)]\tLoss: 0.036820\tTotal Loss: 0.023150\n",
            "Train Epoch: 3 [768/920 (83%)]\tLoss: 0.014672\tTotal Loss: 0.023190\n",
            "Train Epoch: 3 [800/920 (87%)]\tLoss: 0.010039\tTotal Loss: 0.023120\n",
            "Train Epoch: 3 [832/920 (90%)]\tLoss: 0.023729\tTotal Loss: 0.023150\n",
            "Train Epoch: 3 [864/920 (94%)]\tLoss: 0.020578\tTotal Loss: 0.023250\n",
            "Train Epoch: 3 [896/920 (97%)]\tLoss: 0.025312\tTotal Loss: 0.023400\n",
            "Progress: 0.62 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       512\n",
            "           1       0.91      0.91      0.91       340\n",
            "           2       0.98      0.90      0.94        61\n",
            "           3       0.91      0.80      0.85        25\n",
            "           4       0.97      0.98      0.98      4234\n",
            "           5       0.93      0.93      0.93       200\n",
            "           6       0.96      0.98      0.97       519\n",
            "           7       0.98      0.98      0.98      1340\n",
            "           8       0.98      0.99      0.99       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.95      0.92      0.94       989\n",
            "          12       0.91      0.95      0.93       355\n",
            "          13       0.99      0.99      0.99      2273\n",
            "          14       0.99      0.97      0.98      9937\n",
            "          15       0.98      0.99      0.99       306\n",
            "          16       1.00      0.88      0.93        24\n",
            "          18       0.96      0.97      0.96      2465\n",
            "          19       1.00      0.38      0.55        16\n",
            "          20       1.00      0.99      0.99      1815\n",
            "          21       0.94      0.87      0.90       259\n",
            "          22       1.00      1.00      1.00         7\n",
            "          23       0.76      0.85      0.80        26\n",
            "          24       0.99      1.00      1.00      5004\n",
            "          25       1.00      0.62      0.77         8\n",
            "          26       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.92      0.88      0.89     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.980849489860685 Accuracy:  0.9809237995824635\n",
            "Saving best model...\n",
            "Train Epoch: 4 [32/920 (3%)]\tLoss: 0.015996\tTotal Loss: 0.019940\n",
            "Train Epoch: 4 [64/920 (7%)]\tLoss: 0.017601\tTotal Loss: 0.018900\n",
            "Train Epoch: 4 [96/920 (10%)]\tLoss: 0.014881\tTotal Loss: 0.019160\n",
            "Train Epoch: 4 [128/920 (14%)]\tLoss: 0.013475\tTotal Loss: 0.019050\n",
            "Train Epoch: 4 [160/920 (17%)]\tLoss: 0.012737\tTotal Loss: 0.019740\n",
            "Train Epoch: 4 [192/920 (21%)]\tLoss: 0.025646\tTotal Loss: 0.019350\n",
            "Train Epoch: 4 [224/920 (24%)]\tLoss: 0.027570\tTotal Loss: 0.019380\n",
            "Train Epoch: 4 [256/920 (28%)]\tLoss: 0.010991\tTotal Loss: 0.019330\n",
            "Train Epoch: 4 [288/920 (31%)]\tLoss: 0.034588\tTotal Loss: 0.019640\n",
            "Train Epoch: 4 [320/920 (35%)]\tLoss: 0.013587\tTotal Loss: 0.019670\n",
            "Train Epoch: 4 [352/920 (38%)]\tLoss: 0.015134\tTotal Loss: 0.019810\n",
            "Train Epoch: 4 [384/920 (42%)]\tLoss: 0.036506\tTotal Loss: 0.020030\n",
            "Train Epoch: 4 [416/920 (45%)]\tLoss: 0.019263\tTotal Loss: 0.020040\n",
            "Train Epoch: 4 [448/920 (49%)]\tLoss: 0.016722\tTotal Loss: 0.020010\n",
            "Train Epoch: 4 [480/920 (52%)]\tLoss: 0.017754\tTotal Loss: 0.020090\n",
            "Train Epoch: 4 [512/920 (56%)]\tLoss: 0.016434\tTotal Loss: 0.020190\n",
            "Train Epoch: 4 [544/920 (59%)]\tLoss: 0.013973\tTotal Loss: 0.020190\n",
            "Train Epoch: 4 [576/920 (62%)]\tLoss: 0.010403\tTotal Loss: 0.020180\n",
            "Train Epoch: 4 [608/920 (66%)]\tLoss: 0.009472\tTotal Loss: 0.020130\n",
            "Train Epoch: 4 [640/920 (69%)]\tLoss: 0.020960\tTotal Loss: 0.020180\n",
            "Train Epoch: 4 [672/920 (73%)]\tLoss: 0.027687\tTotal Loss: 0.020140\n",
            "Train Epoch: 4 [704/920 (76%)]\tLoss: 0.016653\tTotal Loss: 0.020180\n",
            "Train Epoch: 4 [736/920 (80%)]\tLoss: 0.023324\tTotal Loss: 0.020270\n",
            "Train Epoch: 4 [768/920 (83%)]\tLoss: 0.022271\tTotal Loss: 0.020180\n",
            "Train Epoch: 4 [800/920 (87%)]\tLoss: 0.010296\tTotal Loss: 0.020150\n",
            "Train Epoch: 4 [832/920 (90%)]\tLoss: 0.027162\tTotal Loss: 0.020130\n",
            "Train Epoch: 4 [864/920 (94%)]\tLoss: 0.014605\tTotal Loss: 0.020170\n",
            "Train Epoch: 4 [896/920 (97%)]\tLoss: 0.022602\tTotal Loss: 0.020190\n",
            "Progress: 0.62 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       512\n",
            "           1       0.91      0.91      0.91       340\n",
            "           2       0.98      0.90      0.94        61\n",
            "           3       0.81      0.88      0.85        25\n",
            "           4       0.97      0.99      0.98      4234\n",
            "           5       0.97      0.90      0.93       200\n",
            "           6       0.97      0.98      0.98       519\n",
            "           7       0.99      0.98      0.98      1340\n",
            "           8       0.99      0.99      0.99       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.94      0.93      0.94       989\n",
            "          12       0.92      0.94      0.93       355\n",
            "          13       0.99      0.99      0.99      2273\n",
            "          14       0.98      0.98      0.98      9937\n",
            "          15       0.98      1.00      0.99       306\n",
            "          16       0.91      0.88      0.89        24\n",
            "          18       0.97      0.96      0.97      2465\n",
            "          19       0.86      0.38      0.52        16\n",
            "          20       1.00      0.99      0.99      1815\n",
            "          21       0.91      0.88      0.89       259\n",
            "          22       0.88      1.00      0.93         7\n",
            "          23       0.78      0.81      0.79        26\n",
            "          24       0.99      1.00      0.99      5004\n",
            "          25       1.00      0.75      0.86         8\n",
            "          26       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.91      0.88      0.89     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.9812573043575918 Accuracy:  0.9813152400835073\n",
            "Saving best model...\n",
            "Train Epoch: 5 [32/920 (3%)]\tLoss: 0.012015\tTotal Loss: 0.013980\n",
            "Train Epoch: 5 [64/920 (7%)]\tLoss: 0.023622\tTotal Loss: 0.014760\n",
            "Train Epoch: 5 [96/920 (10%)]\tLoss: 0.006541\tTotal Loss: 0.015920\n",
            "Train Epoch: 5 [128/920 (14%)]\tLoss: 0.016599\tTotal Loss: 0.016130\n",
            "Train Epoch: 5 [160/920 (17%)]\tLoss: 0.013340\tTotal Loss: 0.016200\n",
            "Train Epoch: 5 [192/920 (21%)]\tLoss: 0.015065\tTotal Loss: 0.016160\n",
            "Train Epoch: 5 [224/920 (24%)]\tLoss: 0.018998\tTotal Loss: 0.015880\n",
            "Train Epoch: 5 [256/920 (28%)]\tLoss: 0.014439\tTotal Loss: 0.015970\n",
            "Train Epoch: 5 [288/920 (31%)]\tLoss: 0.015955\tTotal Loss: 0.015820\n",
            "Train Epoch: 5 [320/920 (35%)]\tLoss: 0.016336\tTotal Loss: 0.015840\n",
            "Train Epoch: 5 [352/920 (38%)]\tLoss: 0.019449\tTotal Loss: 0.015810\n",
            "Train Epoch: 5 [384/920 (42%)]\tLoss: 0.027539\tTotal Loss: 0.016030\n",
            "Train Epoch: 5 [416/920 (45%)]\tLoss: 0.010514\tTotal Loss: 0.015910\n",
            "Train Epoch: 5 [448/920 (49%)]\tLoss: 0.006561\tTotal Loss: 0.015850\n",
            "Train Epoch: 5 [480/920 (52%)]\tLoss: 0.018959\tTotal Loss: 0.015980\n",
            "Train Epoch: 5 [512/920 (56%)]\tLoss: 0.029537\tTotal Loss: 0.015980\n",
            "Train Epoch: 5 [544/920 (59%)]\tLoss: 0.035666\tTotal Loss: 0.016070\n",
            "Train Epoch: 5 [576/920 (62%)]\tLoss: 0.010142\tTotal Loss: 0.016150\n",
            "Train Epoch: 5 [608/920 (66%)]\tLoss: 0.016409\tTotal Loss: 0.016090\n",
            "Train Epoch: 5 [640/920 (69%)]\tLoss: 0.018229\tTotal Loss: 0.016200\n",
            "Train Epoch: 5 [672/920 (73%)]\tLoss: 0.007640\tTotal Loss: 0.016180\n",
            "Train Epoch: 5 [704/920 (76%)]\tLoss: 0.014149\tTotal Loss: 0.016240\n",
            "Train Epoch: 5 [736/920 (80%)]\tLoss: 0.010030\tTotal Loss: 0.016250\n",
            "Train Epoch: 5 [768/920 (83%)]\tLoss: 0.022432\tTotal Loss: 0.016240\n",
            "Train Epoch: 5 [800/920 (87%)]\tLoss: 0.034162\tTotal Loss: 0.016340\n",
            "Train Epoch: 5 [832/920 (90%)]\tLoss: 0.026649\tTotal Loss: 0.016350\n",
            "Train Epoch: 5 [864/920 (94%)]\tLoss: 0.008131\tTotal Loss: 0.016310\n",
            "Train Epoch: 5 [896/920 (97%)]\tLoss: 0.023845\tTotal Loss: 0.016390\n",
            "Progress: 0.62 31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       512\n",
            "           1       0.93      0.89      0.91       340\n",
            "           2       1.00      0.93      0.97        61\n",
            "           3       0.73      0.88      0.80        25\n",
            "           4       0.97      0.99      0.98      4234\n",
            "           5       0.91      0.93      0.92       200\n",
            "           6       0.97      0.98      0.97       519\n",
            "           7       0.97      0.99      0.98      1340\n",
            "           8       0.98      0.99      0.99       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.95      0.92      0.93       989\n",
            "          12       0.90      0.95      0.93       355\n",
            "          13       0.99      1.00      0.99      2273\n",
            "          14       0.99      0.97      0.98      9937\n",
            "          15       0.98      0.99      0.99       306\n",
            "          16       0.91      0.88      0.89        24\n",
            "          18       0.96      0.97      0.97      2465\n",
            "          19       0.65      0.81      0.72        16\n",
            "          20       0.99      0.99      0.99      1815\n",
            "          21       0.91      0.89      0.90       259\n",
            "          22       0.88      1.00      0.93         7\n",
            "          23       0.84      0.81      0.82        26\n",
            "          24       0.99      1.00      1.00      5004\n",
            "          25       1.00      0.75      0.86         8\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.94      0.94      0.94     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.9811309209789114 Accuracy:  0.9811325678496868\n",
            "Train Epoch: 6 [32/920 (3%)]\tLoss: 0.030875\tTotal Loss: 0.013820\n",
            "Train Epoch: 6 [64/920 (7%)]\tLoss: 0.017906\tTotal Loss: 0.015160\n",
            "Train Epoch: 6 [96/920 (10%)]\tLoss: 0.004827\tTotal Loss: 0.014270\n",
            "Train Epoch: 6 [128/920 (14%)]\tLoss: 0.020610\tTotal Loss: 0.014570\n",
            "Train Epoch: 6 [160/920 (17%)]\tLoss: 0.008349\tTotal Loss: 0.014630\n",
            "Train Epoch: 6 [192/920 (21%)]\tLoss: 0.012526\tTotal Loss: 0.014500\n",
            "Train Epoch: 6 [224/920 (24%)]\tLoss: 0.022780\tTotal Loss: 0.014290\n",
            "Train Epoch: 6 [256/920 (28%)]\tLoss: 0.015381\tTotal Loss: 0.014020\n",
            "Train Epoch: 6 [288/920 (31%)]\tLoss: 0.008772\tTotal Loss: 0.013890\n",
            "Train Epoch: 6 [320/920 (35%)]\tLoss: 0.013107\tTotal Loss: 0.013840\n",
            "Train Epoch: 6 [352/920 (38%)]\tLoss: 0.010371\tTotal Loss: 0.013810\n",
            "Train Epoch: 6 [384/920 (42%)]\tLoss: 0.013952\tTotal Loss: 0.013850\n",
            "Train Epoch: 6 [416/920 (45%)]\tLoss: 0.012589\tTotal Loss: 0.013670\n",
            "Train Epoch: 6 [448/920 (49%)]\tLoss: 0.006212\tTotal Loss: 0.013580\n",
            "Train Epoch: 6 [480/920 (52%)]\tLoss: 0.011637\tTotal Loss: 0.013640\n",
            "Train Epoch: 6 [512/920 (56%)]\tLoss: 0.037671\tTotal Loss: 0.013890\n",
            "Train Epoch: 6 [544/920 (59%)]\tLoss: 0.013423\tTotal Loss: 0.013970\n",
            "Train Epoch: 6 [576/920 (62%)]\tLoss: 0.017036\tTotal Loss: 0.013960\n",
            "Train Epoch: 6 [608/920 (66%)]\tLoss: 0.011904\tTotal Loss: 0.013930\n",
            "Train Epoch: 6 [640/920 (69%)]\tLoss: 0.017442\tTotal Loss: 0.013900\n",
            "Train Epoch: 6 [672/920 (73%)]\tLoss: 0.009276\tTotal Loss: 0.013890\n",
            "Train Epoch: 6 [704/920 (76%)]\tLoss: 0.018902\tTotal Loss: 0.013920\n",
            "Train Epoch: 6 [736/920 (80%)]\tLoss: 0.010995\tTotal Loss: 0.014020\n",
            "Train Epoch: 6 [768/920 (83%)]\tLoss: 0.014322\tTotal Loss: 0.014010\n",
            "Train Epoch: 6 [800/920 (87%)]\tLoss: 0.005293\tTotal Loss: 0.014010\n",
            "Train Epoch: 6 [832/920 (90%)]\tLoss: 0.011434\tTotal Loss: 0.014040\n",
            "Train Epoch: 6 [864/920 (94%)]\tLoss: 0.021910\tTotal Loss: 0.014090\n",
            "Train Epoch: 6 [896/920 (97%)]\tLoss: 0.012921\tTotal Loss: 0.014080\n",
            "Progress: 0.62 31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       512\n",
            "           1       0.89      0.93      0.91       340\n",
            "           2       1.00      0.90      0.95        61\n",
            "           3       0.91      0.80      0.85        25\n",
            "           4       0.97      0.98      0.97      4234\n",
            "           5       0.95      0.93      0.94       200\n",
            "           6       0.98      0.98      0.98       519\n",
            "           7       0.99      0.97      0.98      1340\n",
            "           8       0.99      0.99      0.99       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.95      0.93      0.94       989\n",
            "          12       0.93      0.94      0.93       355\n",
            "          13       0.99      0.99      0.99      2273\n",
            "          14       0.98      0.98      0.98      9937\n",
            "          15       0.99      0.99      0.99       306\n",
            "          16       1.00      0.88      0.93        24\n",
            "          18       0.97      0.96      0.97      2465\n",
            "          19       0.62      0.50      0.55        16\n",
            "          20       0.99      0.99      0.99      1815\n",
            "          21       0.91      0.90      0.91       259\n",
            "          22       0.88      1.00      0.93         7\n",
            "          23       0.78      0.81      0.79        26\n",
            "          24       0.99      1.00      0.99      5004\n",
            "          25       1.00      0.75      0.86         8\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.94      0.92      0.93     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.9807614560493998 Accuracy:  0.9807933194154489\n",
            "Train Epoch: 7 [32/920 (3%)]\tLoss: 0.006277\tTotal Loss: 0.011620\n",
            "Train Epoch: 7 [64/920 (7%)]\tLoss: 0.009685\tTotal Loss: 0.012120\n",
            "Train Epoch: 7 [96/920 (10%)]\tLoss: 0.008068\tTotal Loss: 0.011830\n",
            "Train Epoch: 7 [128/920 (14%)]\tLoss: 0.003684\tTotal Loss: 0.011810\n",
            "Train Epoch: 7 [160/920 (17%)]\tLoss: 0.014509\tTotal Loss: 0.011530\n",
            "Train Epoch: 7 [192/920 (21%)]\tLoss: 0.010333\tTotal Loss: 0.011750\n",
            "Train Epoch: 7 [224/920 (24%)]\tLoss: 0.006748\tTotal Loss: 0.011550\n",
            "Train Epoch: 7 [256/920 (28%)]\tLoss: 0.014564\tTotal Loss: 0.011570\n",
            "Train Epoch: 7 [288/920 (31%)]\tLoss: 0.010819\tTotal Loss: 0.011500\n",
            "Train Epoch: 7 [320/920 (35%)]\tLoss: 0.011097\tTotal Loss: 0.011560\n",
            "Train Epoch: 7 [352/920 (38%)]\tLoss: 0.011588\tTotal Loss: 0.011620\n",
            "Train Epoch: 7 [384/920 (42%)]\tLoss: 0.003346\tTotal Loss: 0.011550\n",
            "Train Epoch: 7 [416/920 (45%)]\tLoss: 0.014836\tTotal Loss: 0.011610\n",
            "Train Epoch: 7 [448/920 (49%)]\tLoss: 0.021284\tTotal Loss: 0.011610\n",
            "Train Epoch: 7 [480/920 (52%)]\tLoss: 0.021378\tTotal Loss: 0.011630\n",
            "Train Epoch: 7 [512/920 (56%)]\tLoss: 0.024380\tTotal Loss: 0.011640\n",
            "Train Epoch: 7 [544/920 (59%)]\tLoss: 0.008455\tTotal Loss: 0.011770\n",
            "Train Epoch: 7 [576/920 (62%)]\tLoss: 0.017374\tTotal Loss: 0.011900\n",
            "Train Epoch: 7 [608/920 (66%)]\tLoss: 0.004318\tTotal Loss: 0.011850\n",
            "Train Epoch: 7 [640/920 (69%)]\tLoss: 0.017033\tTotal Loss: 0.011910\n",
            "Train Epoch: 7 [672/920 (73%)]\tLoss: 0.010626\tTotal Loss: 0.012050\n",
            "Train Epoch: 7 [704/920 (76%)]\tLoss: 0.006611\tTotal Loss: 0.012080\n",
            "Train Epoch: 7 [736/920 (80%)]\tLoss: 0.004688\tTotal Loss: 0.012030\n",
            "Train Epoch: 7 [768/920 (83%)]\tLoss: 0.011314\tTotal Loss: 0.012010\n",
            "Train Epoch: 7 [800/920 (87%)]\tLoss: 0.015998\tTotal Loss: 0.011990\n",
            "Train Epoch: 7 [832/920 (90%)]\tLoss: 0.012970\tTotal Loss: 0.012060\n",
            "Train Epoch: 7 [864/920 (94%)]\tLoss: 0.012521\tTotal Loss: 0.012020\n",
            "Train Epoch: 7 [896/920 (97%)]\tLoss: 0.003833\tTotal Loss: 0.012000\n",
            "Progress: 0.62 31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       512\n",
            "           1       0.88      0.93      0.91       340\n",
            "           2       1.00      0.90      0.95        61\n",
            "           3       0.88      0.88      0.88        25\n",
            "           4       0.97      0.98      0.98      4234\n",
            "           5       0.93      0.93      0.93       200\n",
            "           6       0.97      0.98      0.97       519\n",
            "           7       0.98      0.98      0.98      1340\n",
            "           8       0.99      0.99      0.99       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.96      0.92      0.94       989\n",
            "          12       0.93      0.93      0.93       355\n",
            "          13       0.99      0.99      0.99      2273\n",
            "          14       0.98      0.98      0.98      9937\n",
            "          15       0.99      0.99      0.99       306\n",
            "          16       1.00      0.88      0.93        24\n",
            "          18       0.96      0.97      0.97      2465\n",
            "          19       0.62      0.50      0.55        16\n",
            "          20       0.99      0.99      0.99      1815\n",
            "          21       0.92      0.89      0.91       259\n",
            "          22       0.88      1.00      0.93         7\n",
            "          23       0.78      0.81      0.79        26\n",
            "          24       0.99      1.00      0.99      5004\n",
            "          25       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.94      0.93      0.94     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.9812829096414609 Accuracy:  0.9813152400835073\n",
            "Saving best model...\n",
            "Train Epoch: 8 [32/920 (3%)]\tLoss: 0.001511\tTotal Loss: 0.009210\n",
            "Train Epoch: 8 [64/920 (7%)]\tLoss: 0.004546\tTotal Loss: 0.009400\n",
            "Train Epoch: 8 [96/920 (10%)]\tLoss: 0.004221\tTotal Loss: 0.009680\n",
            "Train Epoch: 8 [128/920 (14%)]\tLoss: 0.003920\tTotal Loss: 0.009920\n",
            "Train Epoch: 8 [160/920 (17%)]\tLoss: 0.002737\tTotal Loss: 0.009910\n",
            "Train Epoch: 8 [192/920 (21%)]\tLoss: 0.009810\tTotal Loss: 0.010090\n",
            "Train Epoch: 8 [224/920 (24%)]\tLoss: 0.004138\tTotal Loss: 0.010020\n",
            "Train Epoch: 8 [256/920 (28%)]\tLoss: 0.009683\tTotal Loss: 0.010130\n",
            "Train Epoch: 8 [288/920 (31%)]\tLoss: 0.015221\tTotal Loss: 0.010240\n",
            "Train Epoch: 8 [320/920 (35%)]\tLoss: 0.012839\tTotal Loss: 0.010210\n",
            "Train Epoch: 8 [352/920 (38%)]\tLoss: 0.006182\tTotal Loss: 0.010240\n",
            "Train Epoch: 8 [384/920 (42%)]\tLoss: 0.018797\tTotal Loss: 0.010270\n",
            "Train Epoch: 8 [416/920 (45%)]\tLoss: 0.007290\tTotal Loss: 0.010280\n",
            "Train Epoch: 8 [448/920 (49%)]\tLoss: 0.012545\tTotal Loss: 0.010440\n",
            "Train Epoch: 8 [480/920 (52%)]\tLoss: 0.010570\tTotal Loss: 0.010550\n",
            "Train Epoch: 8 [512/920 (56%)]\tLoss: 0.007836\tTotal Loss: 0.010480\n",
            "Train Epoch: 8 [544/920 (59%)]\tLoss: 0.010014\tTotal Loss: 0.010490\n",
            "Train Epoch: 8 [576/920 (62%)]\tLoss: 0.007714\tTotal Loss: 0.010440\n",
            "Train Epoch: 8 [608/920 (66%)]\tLoss: 0.005224\tTotal Loss: 0.010360\n",
            "Train Epoch: 8 [640/920 (69%)]\tLoss: 0.004483\tTotal Loss: 0.010370\n",
            "Train Epoch: 8 [672/920 (73%)]\tLoss: 0.006754\tTotal Loss: 0.010350\n",
            "Train Epoch: 8 [704/920 (76%)]\tLoss: 0.014373\tTotal Loss: 0.010380\n",
            "Train Epoch: 8 [736/920 (80%)]\tLoss: 0.029783\tTotal Loss: 0.010400\n",
            "Train Epoch: 8 [768/920 (83%)]\tLoss: 0.020592\tTotal Loss: 0.010450\n",
            "Train Epoch: 8 [800/920 (87%)]\tLoss: 0.003590\tTotal Loss: 0.010420\n",
            "Train Epoch: 8 [832/920 (90%)]\tLoss: 0.006721\tTotal Loss: 0.010410\n",
            "Train Epoch: 8 [864/920 (94%)]\tLoss: 0.011521\tTotal Loss: 0.010440\n",
            "Train Epoch: 8 [896/920 (97%)]\tLoss: 0.027240\tTotal Loss: 0.010480\n",
            "Progress: 0.62 31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97       512\n",
            "           1       0.91      0.91      0.91       340\n",
            "           2       1.00      0.90      0.95        61\n",
            "           3       0.81      0.88      0.85        25\n",
            "           4       0.98      0.97      0.98      4234\n",
            "           5       0.88      0.93      0.91       200\n",
            "           6       0.97      0.98      0.98       519\n",
            "           7       0.98      0.98      0.98      1340\n",
            "           8       0.99      0.99      0.99       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.96      0.92      0.94       989\n",
            "          12       0.92      0.95      0.93       355\n",
            "          13       0.99      0.99      0.99      2273\n",
            "          14       0.98      0.98      0.98      9937\n",
            "          15       0.99      0.99      0.99       306\n",
            "          16       1.00      0.88      0.93        24\n",
            "          18       0.96      0.98      0.97      2465\n",
            "          19       0.80      0.50      0.62        16\n",
            "          20       0.99      1.00      0.99      1815\n",
            "          21       0.93      0.89      0.91       259\n",
            "          22       0.88      1.00      0.93         7\n",
            "          23       0.78      0.81      0.79        26\n",
            "          24       0.99      1.00      1.00      5004\n",
            "          25       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.95      0.93      0.94     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.9814602945786468 Accuracy:  0.9814979123173277\n",
            "Saving best model...\n",
            "Train Epoch: 9 [32/920 (3%)]\tLoss: 0.008902\tTotal Loss: 0.009900\n",
            "Train Epoch: 9 [64/920 (7%)]\tLoss: 0.005316\tTotal Loss: 0.008810\n",
            "Train Epoch: 9 [96/920 (10%)]\tLoss: 0.002748\tTotal Loss: 0.009190\n",
            "Train Epoch: 9 [128/920 (14%)]\tLoss: 0.004815\tTotal Loss: 0.008860\n",
            "Train Epoch: 9 [160/920 (17%)]\tLoss: 0.006596\tTotal Loss: 0.008820\n",
            "Train Epoch: 9 [192/920 (21%)]\tLoss: 0.007257\tTotal Loss: 0.008700\n",
            "Train Epoch: 9 [224/920 (24%)]\tLoss: 0.010692\tTotal Loss: 0.008990\n",
            "Train Epoch: 9 [256/920 (28%)]\tLoss: 0.002795\tTotal Loss: 0.009160\n",
            "Train Epoch: 9 [288/920 (31%)]\tLoss: 0.004631\tTotal Loss: 0.009040\n",
            "Train Epoch: 9 [320/920 (35%)]\tLoss: 0.015298\tTotal Loss: 0.009050\n",
            "Train Epoch: 9 [352/920 (38%)]\tLoss: 0.002265\tTotal Loss: 0.009000\n",
            "Train Epoch: 9 [384/920 (42%)]\tLoss: 0.010112\tTotal Loss: 0.008890\n",
            "Train Epoch: 9 [416/920 (45%)]\tLoss: 0.007796\tTotal Loss: 0.008880\n",
            "Train Epoch: 9 [448/920 (49%)]\tLoss: 0.018091\tTotal Loss: 0.008870\n",
            "Train Epoch: 9 [480/920 (52%)]\tLoss: 0.004331\tTotal Loss: 0.008930\n",
            "Train Epoch: 9 [512/920 (56%)]\tLoss: 0.007807\tTotal Loss: 0.008940\n",
            "Train Epoch: 9 [544/920 (59%)]\tLoss: 0.022074\tTotal Loss: 0.009070\n",
            "Train Epoch: 9 [576/920 (62%)]\tLoss: 0.015978\tTotal Loss: 0.009090\n",
            "Train Epoch: 9 [608/920 (66%)]\tLoss: 0.009427\tTotal Loss: 0.009120\n",
            "Train Epoch: 9 [640/920 (69%)]\tLoss: 0.008427\tTotal Loss: 0.009170\n",
            "Train Epoch: 9 [672/920 (73%)]\tLoss: 0.009592\tTotal Loss: 0.009170\n",
            "Train Epoch: 9 [704/920 (76%)]\tLoss: 0.002746\tTotal Loss: 0.009160\n",
            "Train Epoch: 9 [736/920 (80%)]\tLoss: 0.003385\tTotal Loss: 0.009170\n",
            "Train Epoch: 9 [768/920 (83%)]\tLoss: 0.003335\tTotal Loss: 0.009170\n",
            "Train Epoch: 9 [800/920 (87%)]\tLoss: 0.002144\tTotal Loss: 0.009140\n",
            "Train Epoch: 9 [832/920 (90%)]\tLoss: 0.006463\tTotal Loss: 0.009180\n",
            "Train Epoch: 9 [864/920 (94%)]\tLoss: 0.014805\tTotal Loss: 0.009210\n",
            "Train Epoch: 9 [896/920 (97%)]\tLoss: 0.005648\tTotal Loss: 0.009190\n",
            "Progress: 0.62 31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       512\n",
            "           1       0.93      0.89      0.91       340\n",
            "           2       1.00      0.90      0.95        61\n",
            "           3       0.73      0.88      0.80        25\n",
            "           4       0.97      0.98      0.98      4234\n",
            "           5       0.95      0.91      0.93       200\n",
            "           6       0.98      0.99      0.98       519\n",
            "           7       0.98      0.98      0.98      1340\n",
            "           8       0.99      0.99      0.99       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.96      0.93      0.94       989\n",
            "          12       0.91      0.94      0.92       355\n",
            "          13       0.99      1.00      0.99      2273\n",
            "          14       0.98      0.98      0.98      9937\n",
            "          15       0.99      0.99      0.99       306\n",
            "          16       1.00      0.88      0.93        24\n",
            "          18       0.97      0.96      0.97      2465\n",
            "          19       0.64      0.44      0.52        16\n",
            "          20       0.99      0.99      0.99      1815\n",
            "          21       0.92      0.89      0.90       259\n",
            "          22       0.88      1.00      0.93         7\n",
            "          23       0.78      0.81      0.79        26\n",
            "          24       0.99      1.00      1.00      5004\n",
            "          25       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.94      0.93      0.93     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.9820605623996775 Accuracy:  0.9821242171189979\n",
            "Saving best model...\n",
            "Train Epoch: 10 [32/920 (3%)]\tLoss: 0.008440\tTotal Loss: 0.006550\n",
            "Train Epoch: 10 [64/920 (7%)]\tLoss: 0.007847\tTotal Loss: 0.007450\n",
            "Train Epoch: 10 [96/920 (10%)]\tLoss: 0.017988\tTotal Loss: 0.007530\n",
            "Train Epoch: 10 [128/920 (14%)]\tLoss: 0.010764\tTotal Loss: 0.007730\n",
            "Train Epoch: 10 [160/920 (17%)]\tLoss: 0.004409\tTotal Loss: 0.007700\n",
            "Train Epoch: 10 [192/920 (21%)]\tLoss: 0.007423\tTotal Loss: 0.007720\n",
            "Train Epoch: 10 [224/920 (24%)]\tLoss: 0.003167\tTotal Loss: 0.007710\n",
            "Train Epoch: 10 [256/920 (28%)]\tLoss: 0.007119\tTotal Loss: 0.007790\n",
            "Train Epoch: 10 [288/920 (31%)]\tLoss: 0.003235\tTotal Loss: 0.007740\n",
            "Train Epoch: 10 [320/920 (35%)]\tLoss: 0.005085\tTotal Loss: 0.007790\n",
            "Train Epoch: 10 [352/920 (38%)]\tLoss: 0.007912\tTotal Loss: 0.007730\n",
            "Train Epoch: 10 [384/920 (42%)]\tLoss: 0.008987\tTotal Loss: 0.007730\n",
            "Train Epoch: 10 [416/920 (45%)]\tLoss: 0.004755\tTotal Loss: 0.007790\n",
            "Train Epoch: 10 [448/920 (49%)]\tLoss: 0.007789\tTotal Loss: 0.007850\n",
            "Train Epoch: 10 [480/920 (52%)]\tLoss: 0.002435\tTotal Loss: 0.007850\n",
            "Train Epoch: 10 [512/920 (56%)]\tLoss: 0.014847\tTotal Loss: 0.007800\n",
            "Train Epoch: 10 [544/920 (59%)]\tLoss: 0.006019\tTotal Loss: 0.007790\n",
            "Train Epoch: 10 [576/920 (62%)]\tLoss: 0.007341\tTotal Loss: 0.007750\n",
            "Train Epoch: 10 [608/920 (66%)]\tLoss: 0.004421\tTotal Loss: 0.007730\n",
            "Train Epoch: 10 [640/920 (69%)]\tLoss: 0.019949\tTotal Loss: 0.007750\n",
            "Train Epoch: 10 [672/920 (73%)]\tLoss: 0.004281\tTotal Loss: 0.007730\n",
            "Train Epoch: 10 [704/920 (76%)]\tLoss: 0.004939\tTotal Loss: 0.007730\n",
            "Train Epoch: 10 [736/920 (80%)]\tLoss: 0.003213\tTotal Loss: 0.007690\n",
            "Train Epoch: 10 [768/920 (83%)]\tLoss: 0.005472\tTotal Loss: 0.007650\n",
            "Train Epoch: 10 [800/920 (87%)]\tLoss: 0.007177\tTotal Loss: 0.007640\n",
            "Train Epoch: 10 [832/920 (90%)]\tLoss: 0.005483\tTotal Loss: 0.007700\n",
            "Train Epoch: 10 [864/920 (94%)]\tLoss: 0.006290\tTotal Loss: 0.007720\n",
            "Train Epoch: 10 [896/920 (97%)]\tLoss: 0.005776\tTotal Loss: 0.007710\n",
            "Progress: 0.62 31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       512\n",
            "           1       0.91      0.91      0.91       340\n",
            "           2       0.98      0.92      0.95        61\n",
            "           3       0.91      0.84      0.87        25\n",
            "           4       0.97      0.98      0.98      4234\n",
            "           5       0.93      0.92      0.93       200\n",
            "           6       0.97      0.98      0.98       519\n",
            "           7       0.97      0.98      0.98      1340\n",
            "           8       0.98      0.99      0.98       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.97      0.91      0.94       989\n",
            "          12       0.92      0.94      0.93       355\n",
            "          13       1.00      0.99      0.99      2273\n",
            "          14       0.98      0.98      0.98      9937\n",
            "          15       0.99      0.99      0.99       306\n",
            "          16       1.00      0.88      0.93        24\n",
            "          18       0.97      0.97      0.97      2465\n",
            "          19       0.67      0.38      0.48        16\n",
            "          20       0.99      0.99      0.99      1815\n",
            "          21       0.90      0.90      0.90       259\n",
            "          22       0.88      1.00      0.93         7\n",
            "          23       0.81      0.81      0.81        26\n",
            "          24       0.99      1.00      1.00      5004\n",
            "          25       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.95      0.93      0.93     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.981182890351934 Accuracy:  0.9812630480167015\n",
            "Train Epoch: 11 [32/920 (3%)]\tLoss: 0.001334\tTotal Loss: 0.005700\n",
            "Train Epoch: 11 [64/920 (7%)]\tLoss: 0.003560\tTotal Loss: 0.005960\n",
            "Train Epoch: 11 [96/920 (10%)]\tLoss: 0.011887\tTotal Loss: 0.006060\n",
            "Train Epoch: 11 [128/920 (14%)]\tLoss: 0.006215\tTotal Loss: 0.006300\n",
            "Train Epoch: 11 [160/920 (17%)]\tLoss: 0.008771\tTotal Loss: 0.006350\n",
            "Train Epoch: 11 [192/920 (21%)]\tLoss: 0.003464\tTotal Loss: 0.006270\n",
            "Train Epoch: 11 [224/920 (24%)]\tLoss: 0.025292\tTotal Loss: 0.006450\n",
            "Train Epoch: 11 [256/920 (28%)]\tLoss: 0.003484\tTotal Loss: 0.006480\n",
            "Train Epoch: 11 [288/920 (31%)]\tLoss: 0.003486\tTotal Loss: 0.006470\n",
            "Train Epoch: 11 [320/920 (35%)]\tLoss: 0.003992\tTotal Loss: 0.006520\n",
            "Train Epoch: 11 [352/920 (38%)]\tLoss: 0.015111\tTotal Loss: 0.006580\n",
            "Train Epoch: 11 [384/920 (42%)]\tLoss: 0.002824\tTotal Loss: 0.006520\n",
            "Train Epoch: 11 [416/920 (45%)]\tLoss: 0.004578\tTotal Loss: 0.006550\n",
            "Train Epoch: 11 [448/920 (49%)]\tLoss: 0.004873\tTotal Loss: 0.006570\n",
            "Train Epoch: 11 [480/920 (52%)]\tLoss: 0.008130\tTotal Loss: 0.006540\n",
            "Train Epoch: 11 [512/920 (56%)]\tLoss: 0.001231\tTotal Loss: 0.006510\n",
            "Train Epoch: 11 [544/920 (59%)]\tLoss: 0.004032\tTotal Loss: 0.006460\n",
            "Train Epoch: 11 [576/920 (62%)]\tLoss: 0.006726\tTotal Loss: 0.006490\n",
            "Train Epoch: 11 [608/920 (66%)]\tLoss: 0.003263\tTotal Loss: 0.006510\n",
            "Train Epoch: 11 [640/920 (69%)]\tLoss: 0.019543\tTotal Loss: 0.006560\n",
            "Train Epoch: 11 [672/920 (73%)]\tLoss: 0.004898\tTotal Loss: 0.006590\n",
            "Train Epoch: 11 [704/920 (76%)]\tLoss: 0.005506\tTotal Loss: 0.006590\n",
            "Train Epoch: 11 [736/920 (80%)]\tLoss: 0.003568\tTotal Loss: 0.006660\n",
            "Train Epoch: 11 [768/920 (83%)]\tLoss: 0.000647\tTotal Loss: 0.006640\n",
            "Train Epoch: 11 [800/920 (87%)]\tLoss: 0.009377\tTotal Loss: 0.006630\n",
            "Train Epoch: 11 [832/920 (90%)]\tLoss: 0.002200\tTotal Loss: 0.006620\n",
            "Train Epoch: 11 [864/920 (94%)]\tLoss: 0.008184\tTotal Loss: 0.006610\n",
            "Train Epoch: 11 [896/920 (97%)]\tLoss: 0.003127\tTotal Loss: 0.006650\n",
            "Progress: 0.62 31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97       512\n",
            "           1       0.92      0.92      0.92       340\n",
            "           2       0.98      0.90      0.94        61\n",
            "           3       0.79      0.88      0.83        25\n",
            "           4       0.97      0.99      0.98      4234\n",
            "           5       0.88      0.92      0.89       200\n",
            "           6       0.98      0.98      0.98       519\n",
            "           7       0.99      0.97      0.98      1340\n",
            "           8       0.97      0.99      0.98       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.98      0.98      2777\n",
            "          11       0.95      0.91      0.93       989\n",
            "          12       0.92      0.95      0.93       355\n",
            "          13       0.99      0.99      0.99      2273\n",
            "          14       0.99      0.98      0.98      9937\n",
            "          15       0.99      1.00      0.99       306\n",
            "          16       1.00      0.88      0.93        24\n",
            "          18       0.96      0.97      0.97      2465\n",
            "          19       0.62      0.50      0.55        16\n",
            "          20       1.00      0.99      0.99      1815\n",
            "          21       0.93      0.87      0.90       259\n",
            "          22       0.88      1.00      0.93         7\n",
            "          23       0.78      0.81      0.79        26\n",
            "          24       0.99      1.00      1.00      5004\n",
            "          25       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.94      0.93      0.93     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.9811714443894436 Accuracy:  0.9812108559498957\n",
            "Train Epoch: 12 [32/920 (3%)]\tLoss: 0.008726\tTotal Loss: 0.005090\n",
            "Train Epoch: 12 [64/920 (7%)]\tLoss: 0.011266\tTotal Loss: 0.005130\n",
            "Train Epoch: 12 [96/920 (10%)]\tLoss: 0.009604\tTotal Loss: 0.005440\n",
            "Train Epoch: 12 [128/920 (14%)]\tLoss: 0.006763\tTotal Loss: 0.005430\n",
            "Train Epoch: 12 [160/920 (17%)]\tLoss: 0.003966\tTotal Loss: 0.005600\n",
            "Train Epoch: 12 [192/920 (21%)]\tLoss: 0.002080\tTotal Loss: 0.005700\n",
            "Train Epoch: 12 [224/920 (24%)]\tLoss: 0.006015\tTotal Loss: 0.005720\n",
            "Train Epoch: 12 [256/920 (28%)]\tLoss: 0.002312\tTotal Loss: 0.005700\n",
            "Train Epoch: 12 [288/920 (31%)]\tLoss: 0.012479\tTotal Loss: 0.005860\n",
            "Train Epoch: 12 [320/920 (35%)]\tLoss: 0.000787\tTotal Loss: 0.005900\n",
            "Train Epoch: 12 [352/920 (38%)]\tLoss: 0.008895\tTotal Loss: 0.005860\n",
            "Train Epoch: 12 [384/920 (42%)]\tLoss: 0.007170\tTotal Loss: 0.005870\n",
            "Train Epoch: 12 [416/920 (45%)]\tLoss: 0.001759\tTotal Loss: 0.005930\n",
            "Train Epoch: 12 [448/920 (49%)]\tLoss: 0.005183\tTotal Loss: 0.005910\n",
            "Train Epoch: 12 [480/920 (52%)]\tLoss: 0.003477\tTotal Loss: 0.005870\n",
            "Train Epoch: 12 [512/920 (56%)]\tLoss: 0.005395\tTotal Loss: 0.005940\n",
            "Train Epoch: 12 [544/920 (59%)]\tLoss: 0.013828\tTotal Loss: 0.005930\n",
            "Train Epoch: 12 [576/920 (62%)]\tLoss: 0.003981\tTotal Loss: 0.005960\n",
            "Train Epoch: 12 [608/920 (66%)]\tLoss: 0.002354\tTotal Loss: 0.005870\n",
            "Train Epoch: 12 [640/920 (69%)]\tLoss: 0.012656\tTotal Loss: 0.005890\n",
            "Train Epoch: 12 [672/920 (73%)]\tLoss: 0.006948\tTotal Loss: 0.005920\n",
            "Train Epoch: 12 [704/920 (76%)]\tLoss: 0.005798\tTotal Loss: 0.005900\n",
            "Train Epoch: 12 [736/920 (80%)]\tLoss: 0.006309\tTotal Loss: 0.005970\n",
            "Train Epoch: 12 [768/920 (83%)]\tLoss: 0.002632\tTotal Loss: 0.005940\n",
            "Train Epoch: 12 [800/920 (87%)]\tLoss: 0.006267\tTotal Loss: 0.005910\n",
            "Train Epoch: 12 [832/920 (90%)]\tLoss: 0.007629\tTotal Loss: 0.005980\n",
            "Train Epoch: 12 [864/920 (94%)]\tLoss: 0.007162\tTotal Loss: 0.005980\n",
            "Train Epoch: 12 [896/920 (97%)]\tLoss: 0.005275\tTotal Loss: 0.005950\n",
            "Progress: 0.62 31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       512\n",
            "           1       0.92      0.89      0.91       340\n",
            "           2       1.00      0.95      0.97        61\n",
            "           3       0.79      0.88      0.83        25\n",
            "           4       0.98      0.98      0.98      4234\n",
            "           5       0.89      0.92      0.90       200\n",
            "           6       0.98      0.98      0.98       519\n",
            "           7       0.98      0.98      0.98      1340\n",
            "           8       0.98      0.99      0.98       701\n",
            "           9       1.00      1.00      1.00      4127\n",
            "          10       0.98      0.99      0.98      2777\n",
            "          11       0.96      0.91      0.93       989\n",
            "          12       0.91      0.96      0.93       355\n",
            "          13       0.99      0.99      0.99      2273\n",
            "          14       0.98      0.98      0.98      9937\n",
            "          15       0.98      1.00      0.99       306\n",
            "          16       1.00      0.88      0.93        24\n",
            "          18       0.97      0.96      0.97      2465\n",
            "          19       0.80      0.50      0.62        16\n",
            "          20       0.99      0.99      0.99      1815\n",
            "          21       0.91      0.90      0.90       259\n",
            "          22       0.88      1.00      0.93         7\n",
            "          23       0.88      0.81      0.84        26\n",
            "          24       0.99      1.00      1.00      5004\n",
            "          25       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.98     38320\n",
            "   macro avg       0.95      0.94      0.94     38320\n",
            "weighted avg       0.98      0.98      0.98     38320\n",
            "\n",
            "F1:  0.9818220583179378 Accuracy:  0.9818893528183716\n",
            "FIM!!! early_stop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2')\n",
        "tokenizer.save_pretrained(os.path.join(write_path, 'model'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5_4XJ7se1y_",
        "outputId": "5ea16679-6c18-4fce-eda1-6807344517e5"
      },
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model/model/tokenizer_config.json',\n",
              " 'model/model/special_tokens_map.json',\n",
              " 'model/model/vocab.txt',\n",
              " 'model/model/added_tokens.json',\n",
              " 'model/model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzyIvROce16W",
        "outputId": "b082f77f-56fb-42f0-a5b2-8c9f30b0747c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NUM',\n",
              " 1: 'KS',\n",
              " 2: 'PREP+PROADJ',\n",
              " 3: 'ADV-KS',\n",
              " 4: 'NPROP',\n",
              " 5: 'PDEN',\n",
              " 6: 'PROADJ',\n",
              " 7: 'PCP',\n",
              " 8: 'KC',\n",
              " 9: 'PU',\n",
              " 10: 'PREP',\n",
              " 11: 'ADV',\n",
              " 12: 'PRO-KS',\n",
              " 13: 'ART',\n",
              " 14: 'N',\n",
              " 15: 'PROPESS',\n",
              " 16: 'PREP+PROPESS',\n",
              " 17: 'CUR',\n",
              " 18: 'ADJ',\n",
              " 19: 'IN',\n",
              " 20: 'PREP+ART',\n",
              " 21: 'PROSUB',\n",
              " 22: 'PREP+PRO-KS',\n",
              " 23: 'PREP+PROSUB',\n",
              " 24: 'V',\n",
              " 25: 'PREP+ADV',\n",
              " 26: '<pad>'}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag2id"
      ],
      "metadata": {
        "id": "zWdK9fkJhuBG",
        "outputId": "b1d1a96d-64b4-4428-a296-bcf6b3f4396d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<pad>': 26,\n",
              " 'ADJ': 18,\n",
              " 'ADV': 11,\n",
              " 'ADV-KS': 3,\n",
              " 'ART': 13,\n",
              " 'CUR': 17,\n",
              " 'IN': 19,\n",
              " 'KC': 8,\n",
              " 'KS': 1,\n",
              " 'N': 14,\n",
              " 'NPROP': 4,\n",
              " 'NUM': 0,\n",
              " 'PCP': 7,\n",
              " 'PDEN': 5,\n",
              " 'PREP': 10,\n",
              " 'PREP+ADV': 25,\n",
              " 'PREP+ART': 20,\n",
              " 'PREP+PRO-KS': 22,\n",
              " 'PREP+PROADJ': 2,\n",
              " 'PREP+PROPESS': 16,\n",
              " 'PREP+PROSUB': 23,\n",
              " 'PRO-KS': 12,\n",
              " 'PROADJ': 6,\n",
              " 'PROPESS': 15,\n",
              " 'PROSUB': 21,\n",
              " 'PU': 9,\n",
              " 'V': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"model/model\")\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "nlp_token_class = pipeline('ner', model=model, tokenizer=tokenizer, grouped_entities=True)\n",
        "\n",
        "nlp_token_class('On the other hand , a decline of the arsenic content in hair and nail was observed after withdrawal of the drug .')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu8cN-QSwn5Z",
        "outputId": "bfb54c04-261f-4231-a852-999a6d15cfc6"
      },
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_37',\n",
              "  'score': 0.999373,\n",
              "  'word': 'On',\n",
              "  'start': 0,\n",
              "  'end': 2},\n",
              " {'entity_group': 'LABEL_23',\n",
              "  'score': 0.99949944,\n",
              "  'word': 'the',\n",
              "  'start': 3,\n",
              "  'end': 6},\n",
              " {'entity_group': 'LABEL_30',\n",
              "  'score': 0.9989857,\n",
              "  'word': 'other',\n",
              "  'start': 7,\n",
              "  'end': 12},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.99937445,\n",
              "  'word': 'hand',\n",
              "  'start': 13,\n",
              "  'end': 17},\n",
              " {'entity_group': 'LABEL_38',\n",
              "  'score': 0.9996381,\n",
              "  'word': ',',\n",
              "  'start': 18,\n",
              "  'end': 19},\n",
              " {'entity_group': 'LABEL_23',\n",
              "  'score': 0.9994572,\n",
              "  'word': 'a',\n",
              "  'start': 20,\n",
              "  'end': 21},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.99954236,\n",
              "  'word': 'decline',\n",
              "  'start': 22,\n",
              "  'end': 29},\n",
              " {'entity_group': 'LABEL_37',\n",
              "  'score': 0.99928683,\n",
              "  'word': 'of',\n",
              "  'start': 30,\n",
              "  'end': 32},\n",
              " {'entity_group': 'LABEL_23',\n",
              "  'score': 0.9995347,\n",
              "  'word': 'the',\n",
              "  'start': 33,\n",
              "  'end': 36},\n",
              " {'entity_group': 'LABEL_30',\n",
              "  'score': 0.99941427,\n",
              "  'word': 'arsenic',\n",
              "  'start': 37,\n",
              "  'end': 44},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.99949944,\n",
              "  'word': 'content',\n",
              "  'start': 45,\n",
              "  'end': 52},\n",
              " {'entity_group': 'LABEL_37',\n",
              "  'score': 0.99920964,\n",
              "  'word': 'in',\n",
              "  'start': 53,\n",
              "  'end': 55},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.9992269,\n",
              "  'word': 'hair',\n",
              "  'start': 56,\n",
              "  'end': 60},\n",
              " {'entity_group': 'LABEL_20',\n",
              "  'score': 0.99914134,\n",
              "  'word': 'and',\n",
              "  'start': 61,\n",
              "  'end': 64},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.99922013,\n",
              "  'word': 'nail',\n",
              "  'start': 65,\n",
              "  'end': 69},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.99915695,\n",
              "  'word': 'was',\n",
              "  'start': 70,\n",
              "  'end': 73},\n",
              " {'entity_group': 'LABEL_11',\n",
              "  'score': 0.99897325,\n",
              "  'word': 'observed',\n",
              "  'start': 74,\n",
              "  'end': 82},\n",
              " {'entity_group': 'LABEL_37',\n",
              "  'score': 0.9993942,\n",
              "  'word': 'after',\n",
              "  'start': 83,\n",
              "  'end': 88},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.99956566,\n",
              "  'word': 'withdrawal',\n",
              "  'start': 89,\n",
              "  'end': 99},\n",
              " {'entity_group': 'LABEL_37',\n",
              "  'score': 0.9993222,\n",
              "  'word': 'of',\n",
              "  'start': 100,\n",
              "  'end': 102},\n",
              " {'entity_group': 'LABEL_23',\n",
              "  'score': 0.9995183,\n",
              "  'word': 'the',\n",
              "  'start': 103,\n",
              "  'end': 106},\n",
              " {'entity_group': 'LABEL_29',\n",
              "  'score': 0.9994179,\n",
              "  'word': 'drug',\n",
              "  'start': 107,\n",
              "  'end': 111},\n",
              " {'entity_group': 'LABEL_38',\n",
              "  'score': 0.99960285,\n",
              "  'word': '.',\n",
              "  'start': 112,\n",
              "  'end': 113}]"
            ]
          },
          "metadata": {},
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frase = 'The SM protein derived from the spliced RNA joining BSLF2 to BMLF1 is much the most abundant protein .'\n",
        "doc = nlp_token_class(frase)\n",
        "for d in doc:\n",
        "  print(d)\n",
        "  tag = d['entity_group']\n",
        "  text = frase[d['start']:d['end']]\n",
        "  print(tag)\n",
        "  print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTO5vZykKbb5",
        "outputId": "abafe259-b59c-40a6-b5c8-c37bbc51ce9c"
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'entity_group': 'LABEL_23', 'score': 0.999495, 'word': 'The', 'start': 0, 'end': 3}\n",
            "LABEL_23\n",
            "The\n",
            "{'entity_group': 'LABEL_29', 'score': 0.99592054, 'word': 'SM protein', 'start': 4, 'end': 14}\n",
            "LABEL_29\n",
            "SM protein\n",
            "{'entity_group': 'LABEL_11', 'score': 0.998184, 'word': 'derived', 'start': 15, 'end': 22}\n",
            "LABEL_11\n",
            "derived\n",
            "{'entity_group': 'LABEL_37', 'score': 0.99927515, 'word': 'from', 'start': 23, 'end': 27}\n",
            "LABEL_37\n",
            "from\n",
            "{'entity_group': 'LABEL_23', 'score': 0.99948335, 'word': 'the', 'start': 28, 'end': 31}\n",
            "LABEL_23\n",
            "the\n",
            "{'entity_group': 'LABEL_11', 'score': 0.9971042, 'word': 'spliced', 'start': 32, 'end': 39}\n",
            "LABEL_11\n",
            "spliced\n",
            "{'entity_group': 'LABEL_29', 'score': 0.9980102, 'word': 'RNA', 'start': 40, 'end': 43}\n",
            "LABEL_29\n",
            "RNA\n",
            "{'entity_group': 'LABEL_14', 'score': 0.9972887, 'word': 'joining', 'start': 44, 'end': 51}\n",
            "LABEL_14\n",
            "joining\n",
            "{'entity_group': 'LABEL_29', 'score': 0.9994783, 'word': 'BSLF2', 'start': 52, 'end': 57}\n",
            "LABEL_29\n",
            "BSLF2\n",
            "{'entity_group': 'LABEL_7', 'score': 0.99905723, 'word': 'to', 'start': 58, 'end': 60}\n",
            "LABEL_7\n",
            "to\n",
            "{'entity_group': 'LABEL_29', 'score': 0.99952424, 'word': 'BMLF1', 'start': 61, 'end': 66}\n",
            "LABEL_29\n",
            "BMLF1\n",
            "{'entity_group': 'LABEL_12', 'score': 0.99883753, 'word': 'is', 'start': 67, 'end': 69}\n",
            "LABEL_12\n",
            "is\n",
            "{'entity_group': 'LABEL_35', 'score': 0.997797, 'word': 'much', 'start': 70, 'end': 74}\n",
            "LABEL_35\n",
            "much\n",
            "{'entity_group': 'LABEL_23', 'score': 0.99941623, 'word': 'the', 'start': 75, 'end': 78}\n",
            "LABEL_23\n",
            "the\n",
            "{'entity_group': 'LABEL_32', 'score': 0.9752339, 'word': 'most', 'start': 79, 'end': 83}\n",
            "LABEL_32\n",
            "most\n",
            "{'entity_group': 'LABEL_30', 'score': 0.9991892, 'word': 'abundant', 'start': 84, 'end': 92}\n",
            "LABEL_30\n",
            "abundant\n",
            "{'entity_group': 'LABEL_29', 'score': 0.9992667, 'word': 'protein', 'start': 93, 'end': 100}\n",
            "LABEL_29\n",
            "protein\n",
            "{'entity_group': 'LABEL_38', 'score': 0.9995664, 'word': '.', 'start': 101, 'end': 102}\n",
            "LABEL_38\n",
            ".\n"
          ]
        }
      ]
    }
  ]
}